# Repository Structure

This document provides a professional overview of the WorkZone repository organization.

## ğŸ“ Root Directory Structure

```
workzone/
â”œâ”€â”€ src/workzone/           # Production source code
â”œâ”€â”€ tests/                  # Test suites
â”œâ”€â”€ scripts/                # Application entry points
â”œâ”€â”€ notebooks/              # Jupyter notebooks for analysis
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ configs/                # Configuration files
â”œâ”€â”€ data/                   # Datasets (gitignored)
â”œâ”€â”€ outputs/                # Processing results (gitignored)
â”œâ”€â”€ weights/                # Model weights (gitignored)
â””â”€â”€ README.md               # Main documentation
```

## ğŸ”§ Production Code (`src/workzone/`)

**Purpose**: Production-ready Python package for construction zone detection.

```
src/workzone/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ detection/              # YOLO detection and multi-modal fusion
â”‚   â”œâ”€â”€ yolo_detector.py    # Core YOLOv12 detection
â”‚   â”œâ”€â”€ clip_verifier.py    # CLIP semantic verification
â”‚   â””â”€â”€ fusion.py           # Score fusion logic
â”œâ”€â”€ ocr/                    # OCR text extraction
â”‚   â”œâ”€â”€ text_detector.py    # PaddleOCR detection
â”‚   â””â”€â”€ text_classifier.py  # Text semantic classification (97.7% accuracy)
â”œâ”€â”€ state_machine/          # Temporal state tracking
â”‚   â””â”€â”€ workzone_tracker.py # State machine logic
â”œâ”€â”€ models/                 # ML models
â”‚   â”œâ”€â”€ scene_context.py    # Scene classification (Highway/Urban/Suburban)
â”‚   â”œâ”€â”€ per_cue_verification.py  # Per-cue CLIP verification
â”‚   â””â”€â”€ trajectory_tracking.py   # Motion plausibility tracking
â”œâ”€â”€ apps/                   # Applications
â”‚   â”œâ”€â”€ streamlit/          # Web interfaces
â”‚   â””â”€â”€ cli/                # Command-line tools
â””â”€â”€ utils/                  # Shared utilities
```

**Key Features**:
- YOLO12s object detection (50 classes)
- CLIP semantic verification (global + per-cue)
- PaddleOCR text extraction with 97.7% classification accuracy
- Scene context classification (92.8% accuracy)
- Per-cue confidence tracking (5 cue types)
- Motion plausibility from trajectory tracking
- Adaptive state machine with temporal persistence

## ğŸ§ª Testing (`tests/`)

```
tests/
â”œâ”€â”€ test_config.py          # Configuration tests
â”œâ”€â”€ test_models.py          # Model loading tests
â”œâ”€â”€ test_pipelines.py       # End-to-end pipeline tests
â”œâ”€â”€ conftest.py             # PyTest configuration
â””â”€â”€ exploratory/            # Development test scripts
    â”œâ”€â”€ README.md           # Exploratory tests documentation
    â”œâ”€â”€ test_ocr*.py        # OCR development tests
    â”œâ”€â”€ test_classifier_improved.py  # Classifier validation (97.7%)
    â””â”€â”€ analyze_*.py        # Analysis scripts
```

**Testing Standards**:
- Production tests: `tests/test_*.py` (pytest suite)
- Exploratory tests: `tests/exploratory/` (development only)
- Coverage target: >80% for production code

## ğŸ“œ Scripts (`scripts/`)

**Purpose**: Application entry points for running the main applications.

```
scripts/
â”œâ”€â”€ jetson_app.py                   # Main Jetson application
â”œâ”€â”€ jetson_cli_app.py               # CLI application for Jetson
â”œâ”€â”€ jetson_launcher.py              # GUI launcher for Jetson
â”œâ”€â”€ jetson_launcher_sota.py         # Experimental GUI launcher
â””â”€â”€ launch_streamlit.sh             # Script to launch the Streamlit app
```

## ğŸ› ï¸ Tools (`tools/`)

**Purpose**: Automation, utility, and analysis scripts.

```
tools/
â”œâ”€â”€ download_models.sh              # Download pre-trained weights
â”œâ”€â”€ process_video_fusion.py         # Batch video processing
â”œâ”€â”€ optimize_for_jetson.py          # Optimize models for Jetson
â”œâ”€â”€ mine_hard_negatives.py          # Hard-negative mining
â”œâ”€â”€ review_hard_negatives.py        # Human-in-the-loop review
â””â”€â”€ analysis/                       # Analysis scripts
    â””â”€â”€ ...
```

## ğŸ“Š Notebooks (`notebooks/`)

**Purpose**: Interactive analysis and experimentation.

```
notebooks/
â”œâ”€â”€ 01_workzone_yolo_setup.ipynb        # YOLO setup and training
â”œâ”€â”€ 02_workzone_yolo_train_eval.ipynb   # Training evaluation
â”œâ”€â”€ 03_workzone_yolo_video_demo.ipynb   # Video inference demo
â”œâ”€â”€ 04_workzone_video_state_machine.ipynb  # State machine testing
â”œâ”€â”€ 05_workzone_video_timeline_calibration.ipynb  # Threshold tuning
â”œâ”€â”€ 06_triggered_vlm_semantic_verification.ipynb  # CLIP integration
â””â”€â”€ 07_phase1_4_scene_context.ipynb     # Scene context analysis
```

## ğŸ“š Documentation (`docs/`)

```
docs/
â”œâ”€â”€ README.md                       # Documentation index
â”œâ”€â”€ REPOSITORY_STRUCTURE.md         # This guide
â”œâ”€â”€ MODEL_REGISTRY.md               # Model registry
â”œâ”€â”€ guides/
â”‚   â””â”€â”€ QUICKSTART.md               # Quick start
â”œâ”€â”€ technical/                      # Technical docs
â”‚   â”œâ”€â”€ OCR_IMPROVEMENTS.md         # OCR (97.7%)
â”‚   â””â”€â”€ OCR_REALTIME_STRATEGY.md    # Jetson deployment
â”œâ”€â”€ phase1_4/                       # Phase 1.4
â”‚   â”œâ”€â”€ PHASE1_4.md
â”‚   â””â”€â”€ PHASE1_4_SCENE_CONTEXT.md
â”œâ”€â”€ reports/                        # Training reports
â””â”€â”€ archive/                        # Historical docs
```

## âš™ï¸ Configuration (`configs/`)

```
configs/
â”œâ”€â”€ config.yaml                         # Main system configuration
â”œâ”€â”€ motion_cue_config.yaml              # Motion detection config
â””â”€â”€ multi_cue_config.yaml               # Multi-cue fusion config
```

## ğŸ“ Data (`data/`) - Gitignored

**Purpose**: Dataset storage (not tracked in git).

```
data/
â”œâ”€â”€ 00_README.md                        # Dataset documentation
â”œâ”€â”€ 00_DATASET_METADATA.json            # Metadata
â”œâ”€â”€ DATA_ORGANIZATION_PLAN.md           # Organization guide
â”œâ”€â”€ QUICKSTART.md                       # Data quickstart
â”œâ”€â”€ 01_raw/                             # Raw annotations
â”œâ”€â”€ 02_processed/                       # Processed datasets
â”œâ”€â”€ 03_demo/                            # Demo videos
â”œâ”€â”€ 04_derivatives/                     # Derived datasets
â””â”€â”€ 05_workzone_yolo/                   # YOLO training data
```

## ğŸ“¤ Outputs (`outputs/`) - Gitignored

**Purpose**: Processing results and artifacts.

```
outputs/
â”œâ”€â”€ ocr_intensive_test_results.csv      # OCR test results (1,195 samples)
â”œâ”€â”€ ocr_reprocessed_improved.csv            # Improved reprocessing results
â”œâ”€â”€ phase1_1_integrated.csv             # Phase 1.1 results
â”œâ”€â”€ phase1_3_demo/                      # Phase 1.3 demo outputs
â”œâ”€â”€ phase1_4_complete_demo/             # Phase 1.4 demo outputs
â”œâ”€â”€ phase1_4_evaluation/                # Phase 1.4 evaluation
â”œâ”€â”€ hardneg_mining/                     # Hard-negative mining results
â””â”€â”€ hardneg_preview/                    # Hard-negative preview images
```

## ğŸ¯ Model Weights (`weights/`) - Gitignored

**Purpose**: Pre-trained model checkpoints.

```
weights/
â”œâ”€â”€ bestv12.pt                          # YOLO12s baseline
â”œâ”€â”€ yolo12s_fusion_baseline.pt          # Fusion baseline
â”œâ”€â”€ scene_context_classifier.pt         # Scene context model
â””â”€â”€ .gitkeep                            # Placeholder
```

## ğŸ”§ Configuration Files

```
workzone/
â”œâ”€â”€ pyproject.toml                      # Poetry dependencies
â”œâ”€â”€ requirements.txt                    # Pip dependencies
â”œâ”€â”€ setup.sh                            # Environment setup script
â”œâ”€â”€ Makefile                            # Build automation
â”œâ”€â”€ .gitignore                          # Git ignore rules
â””â”€â”€ APP_TESTING_GUIDE.md                # Application testing guide
```

## ğŸ“‹ Development Workflow

### 1. Adding New Features

```bash
# 1. Create feature in src/workzone/
# 2. Add tests in tests/
# 3. Document in docs/
# 4. Update README.md
```

### 2. Running Tests

```bash
# Production tests
pytest tests/

# Exploratory tests (optional)
python tests/exploratory/test_classifier_improved.py
```

### 3. Processing Videos

```bash
# CLI batch processing
python tools/process_video_fusion.py video.mp4 --output-dir outputs/

# Web interface
streamlit run src/workzone/apps/streamlit/app_phase2_1_evaluation.py
```

## ğŸš€ Deployment

### Jetson Orin Preparation

```bash
# Optimize the models for Jetson
python tools/optimize_for_jetson.py

# Convert to TensorRT
trtexec --onnx=model.onnx --saveEngine=model.trt --fp16
```

**Performance Targets**:
- YOLO: 15-20ms per frame
- OCR: 50-80ms per frame (1 Hz sampling)
- Scene Context: 5-10ms per frame
- **Total**: ~30 FPS real-time

## ğŸ“Š Key Metrics

| Component | Accuracy/Performance |
|-----------|---------------------|
| YOLO Detection | 84.6% FP reduction |
| Scene Context | 92.8% accuracy |
| OCR Classification | 97.7% test set accuracy |
| OCR Useful Rate | 39% (up from 26%) |
| System Throughput | 85 FPS (A100), 30 FPS (Jetson) |

## ğŸ“– Additional Resources

- [Main README](../README.md) - Project overview
- [APP_TESTING_GUIDE.md](../APP_TESTING_GUIDE.md) - Testing guide
- [docs/README.md](README.md) - Documentation index
- [MODEL_REGISTRY.md](MODEL_REGISTRY.md) - Model performance
- [technical/OCR_IMPROVEMENTS.md](technical/OCR_IMPROVEMENTS.md) - OCR improvements report

## ğŸ† Competition Ready

This repository is organized for professional presentation in the ESV competition:

âœ… Clean code structure  
âœ… Comprehensive documentation  
âœ… Production-ready tests  
âœ… Performance benchmarks  
âœ… Deployment guides  
âœ… Performance results documented  

**Status**: Ready for evaluation and deployment.
