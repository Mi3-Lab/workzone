{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02efccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val json exists: True\n",
      "YOLO model exists: True\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports and basic paths\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# Paths for your repo\n",
    "DATA_DIR = Path(\"data\")\n",
    "ANN_DIR = DATA_DIR / \"annotations\"\n",
    "IMG_DIR = DATA_DIR / \"images\"\n",
    "\n",
    "VAL_JSON = ANN_DIR / \"instances_val_gps_split_with_signs.json\"\n",
    "YOLO_MODEL_PATH = Path(\"best.pt\")\n",
    "\n",
    "print(\"Val json exists:\", VAL_JSON.exists())\n",
    "print(\"YOLO model exists:\", YOLO_MODEL_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f03062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val images: 2098\n",
      "Val annotations: 21261\n",
      "Num categories: 49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'Police Officer'),\n",
       " (2, 'Police Vehicle'),\n",
       " (3, 'Cone'),\n",
       " (4, 'Fence'),\n",
       " (5, 'Drum'),\n",
       " (6, 'Barricade'),\n",
       " (7, 'Barrier'),\n",
       " (8, 'Work Vehicle'),\n",
       " (9, 'Vertical Panel'),\n",
       " (10, 'Tubular Marker'),\n",
       " (11, 'Arrow Board'),\n",
       " (12, 'Bike Lane'),\n",
       " (13, 'Work Equipment'),\n",
       " (14, 'Worker'),\n",
       " (15, 'Other Roadwork Objects'),\n",
       " (16, 'Temporary Traffic Control Message Board'),\n",
       " (17, 'Temporary Traffic Control Sign'),\n",
       " (19, 'Temporary Traffic Control Sign: left arrow'),\n",
       " (20, 'Temporary Traffic Control Sign: right arrow'),\n",
       " (21, 'Temporary Traffic Control Sign: up arrow'),\n",
       " (22, 'Temporary Traffic Control Sign: left chevron'),\n",
       " (23, 'Temporary Traffic Control Sign: right lane ends sign'),\n",
       " (24, 'Temporary Traffic Control Sign: two lane shift arrows'),\n",
       " (25, 'Temporary Traffic Control Sign: right chevron'),\n",
       " (26, 'Temporary Traffic Control Sign: lane shift arrow'),\n",
       " (27, 'Temporary Traffic Control Sign: up diagonal right arrow'),\n",
       " (28, 'Temporary Traffic Control Sign: left lane ends sign'),\n",
       " (29, 'Temporary Traffic Control Sign: bent left arrow'),\n",
       " (30, 'Temporary Traffic Control Sign: flagger'),\n",
       " (31, 'Temporary Traffic Control Sign: bent right arrow'),\n",
       " (32, 'Temporary Traffic Control Sign: no left turn'),\n",
       " (33, 'Temporary Traffic Control Sign: pedestrian: right arrow'),\n",
       " (34, 'Temporary Traffic Control Sign: pedestrian: left arrow'),\n",
       " (35, 'Temporary Traffic Control Sign: up diagonal left arrow'),\n",
       " (36, 'Temporary Traffic Control Sign: pedestrian'),\n",
       " (37, 'Temporary Traffic Control Sign: no right turn'),\n",
       " (38, 'Temporary Traffic Control Sign: bi-directional arrow'),\n",
       " (39, 'Temporary Traffic Control Sign: two upward diagonal arrows'),\n",
       " (40, 'Temporary Traffic Control Sign: curved right arrow'),\n",
       " (41, 'Temporary Traffic Control Sign: down diagonal left arrow'),\n",
       " (42, 'Temporary Traffic Control Sign: do not enter sign'),\n",
       " (43, 'Temporary Traffic Control Sign: worker'),\n",
       " (44, 'Temporary Traffic Control Sign: bicycle'),\n",
       " (45, 'Temporary Traffic Control Sign: two downward diagonal arrows'),\n",
       " (46, 'Temporary Traffic Control Sign: curved left arrow'),\n",
       " (47, 'Temporary Traffic Control Sign: curved left arrow, curved right arrow'),\n",
       " (48, 'Temporary Traffic Control Sign: work vehicle'),\n",
       " (49, 'Temporary Traffic Control Sign: traffic signal'),\n",
       " (50, 'Temporary Traffic Control Sign: up arrow. stop sign')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Load COCO val and build image + category dicts\n",
    "\n",
    "def load_coco(path: Path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "coco_val = load_coco(VAL_JSON)\n",
    "\n",
    "print(\"Val images:\", len(coco_val[\"images\"]))\n",
    "print(\"Val annotations:\", len(coco_val[\"annotations\"]))\n",
    "print(\"Num categories:\", len(coco_val[\"categories\"]))\n",
    "\n",
    "# image_id -> image_info\n",
    "images_by_id = {img[\"id\"]: img for img in coco_val[\"images\"]}\n",
    "\n",
    "# category_id -> name\n",
    "cat_id_to_name = {c[\"id\"]: c[\"name\"] for c in coco_val[\"categories\"]}\n",
    "list(cat_id_to_name.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86bb61ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Police Officer', 1: 'Police Vehicle', 2: 'Cone', 3: 'Fence', 4: 'Drum', 5: 'Barricade', 6: 'Barrier', 7: 'Work Vehicle', 8: 'Vertical Panel', 9: 'Tubular Marker', 10: 'Arrow Board', 11: 'Bike Lane', 12: 'Work Equipment', 13: 'Worker', 14: 'Other Roadwork Objects', 15: 'Temporary Traffic Control Message Board', 16: 'Temporary Traffic Control Sign', 17: 'Temporary Traffic Control Sign: left arrow', 18: 'Temporary Traffic Control Sign: right arrow', 19: 'Temporary Traffic Control Sign: up arrow', 20: 'Temporary Traffic Control Sign: left chevron', 21: 'Temporary Traffic Control Sign: right lane ends sign', 22: 'Temporary Traffic Control Sign: two lane shift arrows', 23: 'Temporary Traffic Control Sign: right chevron', 24: 'Temporary Traffic Control Sign: lane shift arrow', 25: 'Temporary Traffic Control Sign: up diagonal right arrow', 26: 'Temporary Traffic Control Sign: left lane ends sign', 27: 'Temporary Traffic Control Sign: bent left arrow', 28: 'Temporary Traffic Control Sign: flagger', 29: 'Temporary Traffic Control Sign: bent right arrow', 30: 'Temporary Traffic Control Sign: no left turn', 31: 'Temporary Traffic Control Sign: pedestrian: right arrow', 32: 'Temporary Traffic Control Sign: pedestrian: left arrow', 33: 'Temporary Traffic Control Sign: up diagonal left arrow', 34: 'Temporary Traffic Control Sign: pedestrian', 35: 'Temporary Traffic Control Sign: no right turn', 36: 'Temporary Traffic Control Sign: bi-directional arrow', 37: 'Temporary Traffic Control Sign: two upward diagonal arrows', 38: 'Temporary Traffic Control Sign: curved right arrow', 39: 'Temporary Traffic Control Sign: down diagonal left arrow', 40: 'Temporary Traffic Control Sign: do not enter sign', 41: 'Temporary Traffic Control Sign: worker', 42: 'Temporary Traffic Control Sign: bicycle', 43: 'Temporary Traffic Control Sign: two downward diagonal arrows', 44: 'Temporary Traffic Control Sign: curved left arrow', 45: 'Temporary Traffic Control Sign: curved left arrow, curved right arrow', 46: 'Temporary Traffic Control Sign: work vehicle', 47: 'Temporary Traffic Control Sign: traffic signal', 48: 'Temporary Traffic Control Sign: up arrow, stop sign'}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(YOLO_MODEL_PATH)\n",
    "\n",
    "print(model.names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27d8c002",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'annotations/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m ann = json.load(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mannotations/train.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      5\u001b[39m cats = {cat[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m]: cat[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m ann[\u001b[33m\"\u001b[39m\u001b[33mcategories\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(cats), cats)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/workzone/workzone/lib/python3.12/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'annotations/train.json'"
     ]
    }
   ],
   "source": [
    "import json, pathlib\n",
    "\n",
    "ann = json.load(open(\"annotations/train.json\"))\n",
    "\n",
    "cats = {cat[\"id\"]: cat[\"name\"] for cat in ann[\"categories\"]}\n",
    "print(len(cats), cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722f7b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene label counts: Counter({'workzone_ahead': 2041, 'lane_shift': 56})\n"
     ]
    }
   ],
   "source": [
    "# 3. Map scene_level_tags.travel_alteration to a simple scene label\n",
    "\n",
    "def get_scene_label(img_dict):\n",
    "    \"\"\"\n",
    "    Use scene_level_tags.travel_alteration to get a coarse scene label.\n",
    "    lane_shift or workzone_ahead or None.\n",
    "    \"\"\"\n",
    "    tags = img_dict.get(\"scene_level_tags\", {})\n",
    "    travel_alteration = tags.get(\"travel_alteration\", [])\n",
    "\n",
    "    # sometimes list, sometimes string\n",
    "    if isinstance(travel_alteration, list):\n",
    "        travel_alteration = travel_alteration[0] if travel_alteration else None\n",
    "\n",
    "    if travel_alteration is None:\n",
    "        return None\n",
    "\n",
    "    txt = str(travel_alteration).lower()\n",
    "\n",
    "    if \"lane shift\" in txt:\n",
    "        return \"lane_shift\"\n",
    "\n",
    "    # anything else non empty is considered generic workzone ahead\n",
    "    return \"workzone_ahead\"\n",
    "\n",
    "# quick check of distribution\n",
    "scene_labels = [get_scene_label(img) for img in coco_val[\"images\"]]\n",
    "from collections import Counter\n",
    "print(\"Scene label counts:\", Counter([s for s in scene_labels if s is not None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590bc5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmapped category names: ['Bike Lane']\n"
     ]
    }
   ],
   "source": [
    "# 4. Define semantic groups for categories\n",
    "\n",
    "CHANNELIZATION = {\n",
    "    \"Cone\",\n",
    "    \"Drum\",\n",
    "    \"Barricade\",\n",
    "    \"Barrier\",\n",
    "    \"Vertical Panel\",\n",
    "    \"Tubular Marker\",\n",
    "    \"Fence\",\n",
    "}\n",
    "\n",
    "WORKERS = {\n",
    "    \"Worker\",\n",
    "    \"Police Officer\",\n",
    "}\n",
    "\n",
    "VEHICLES = {\n",
    "    \"Work Vehicle\",\n",
    "    \"Police Vehicle\",\n",
    "}\n",
    "\n",
    "MESSAGE_BOARD = {\n",
    "    \"Temporary Traffic Control Message Board\",\n",
    "    \"Arrow Board\",\n",
    "}\n",
    "\n",
    "TTC_SIGNS = {\n",
    "    \"Temporary Traffic Control Sign\",\n",
    "    \"Temporary Traffic Control Sign: left arrow\",\n",
    "    \"Temporary Traffic Control Sign: right arrow\",\n",
    "    \"Temporary Traffic Control Sign: up arrow\",\n",
    "    \"Temporary Traffic Control Sign: left chevron\",\n",
    "    \"Temporary Traffic Control Sign: right lane ends sign\",\n",
    "    \"Temporary Traffic Control Sign: two lane shift arrows\",\n",
    "    \"Temporary Traffic Control Sign: right chevron\",\n",
    "    \"Temporary Traffic Control Sign: lane shift arrow\",\n",
    "    \"Temporary Traffic Control Sign: up diagonal right arrow\",\n",
    "    \"Temporary Traffic Control Sign: left lane ends sign\",\n",
    "    \"Temporary Traffic Control Sign: bent left arrow\",\n",
    "    \"Temporary Traffic Control Sign: flagger\",\n",
    "    \"Temporary Traffic Control Sign: bent right arrow\",\n",
    "    \"Temporary Traffic Control Sign: no left turn\",\n",
    "    \"Temporary Traffic Control Sign: pedestrian: right arrow\",\n",
    "    \"Temporary Traffic Control Sign: pedestrian: left arrow\",\n",
    "    \"Temporary Traffic Control Sign: up diagonal left arrow\",\n",
    "    \"Temporary Traffic Control Sign: pedestrian\",\n",
    "    \"Temporary Traffic Control Sign: no right turn\",\n",
    "    \"Temporary Traffic Control Sign: bi-directional arrow\",\n",
    "    \"Temporary Traffic Control Sign: two upward diagonal arrows\",\n",
    "    \"Temporary Traffic Control Sign: curved right arrow\",\n",
    "    \"Temporary Traffic Control Sign: down diagonal left arrow\",\n",
    "    \"Temporary Traffic Control Sign: do not enter sign\",\n",
    "    \"Temporary Traffic Control Sign: worker\",\n",
    "    \"Temporary Traffic Control Sign: bicycle\",\n",
    "    \"Temporary Traffic Control Sign: two downward diagonal arrows\",\n",
    "    \"Temporary Traffic Control Sign: curved left arrow\",\n",
    "    \"Temporary Traffic Control Sign: curved left arrow, curved right arrow\",\n",
    "    \"Temporary Traffic Control Sign: work vehicle\",\n",
    "    \"Temporary Traffic Control Sign: traffic signal\",\n",
    "    \"Temporary Traffic Control Sign: up arrow. stop sign\",\n",
    "}\n",
    "\n",
    "OTHER_ROADWORK = {\n",
    "    \"Work Equipment\",\n",
    "    \"Other Roadwork Objects\",\n",
    "}\n",
    "\n",
    "name_to_group = {}\n",
    "for n in CHANNELIZATION:\n",
    "    name_to_group[n] = \"channelization\"\n",
    "for n in WORKERS:\n",
    "    name_to_group[n] = \"workers\"\n",
    "for n in VEHICLES:\n",
    "    name_to_group[n] = \"vehicles\"\n",
    "for n in MESSAGE_BOARD:\n",
    "    name_to_group[n] = \"message_board\"\n",
    "for n in TTC_SIGNS:\n",
    "    name_to_group[n] = \"ttc_signs\"\n",
    "for n in OTHER_ROADWORK:\n",
    "    name_to_group[n] = \"other_roadwork\"\n",
    "\n",
    "unmapped = [n for n in cat_id_to_name.values() if n not in name_to_group]\n",
    "print(\"Unmapped category names:\", unmapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8040e0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): A2C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Sequential(\n",
       "            (0): ABlock(\n",
       "              (attn): AAttn(\n",
       "                (qkv): Conv(\n",
       "                  (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (proj): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (pe): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (mlp): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ABlock(\n",
       "              (attn): AAttn(\n",
       "                (qkv): Conv(\n",
       "                  (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (proj): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (pe): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (mlp): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): A2C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Sequential(\n",
       "            (0): ABlock(\n",
       "              (attn): AAttn(\n",
       "                (qkv): Conv(\n",
       "                  (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (proj): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (pe): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (mlp): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ABlock(\n",
       "              (attn): AAttn(\n",
       "                (qkv): Conv(\n",
       "                  (conv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (proj): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "                (pe): Conv(\n",
       "                  (conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256, bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (mlp): Sequential(\n",
       "                (0): Conv(\n",
       "                  (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (1): Conv(\n",
       "                  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (10): Concat()\n",
       "      (11): A2C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (13): Concat()\n",
       "      (14): A2C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (16): Concat()\n",
       "      (17): A2C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (19): Concat()\n",
       "      (20): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(128, 49, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(128, 49, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "                (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(128, 49, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Load YOLOv12 model\n",
    "\n",
    "yolo_model = YOLO(str(YOLO_MODEL_PATH))\n",
    "yolo_model.to(\"cuda\")  # or \"cpu\" if needed\n",
    "yolo_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d78c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Helpers to bin objects in left/mid/right and near/mid/far\n",
    "\n",
    "def compute_position_bins(x_center_norm):\n",
    "    \"\"\"\n",
    "    x_center_norm in [0, 1].\n",
    "    Returns 'left', 'mid', or 'right'.\n",
    "    \"\"\"\n",
    "    if x_center_norm < 1 / 3:\n",
    "        return \"left\"\n",
    "    elif x_center_norm < 2 / 3:\n",
    "        return \"mid\"\n",
    "    else:\n",
    "        return \"right\"\n",
    "\n",
    "\n",
    "def area_bin(area_norm):\n",
    "    \"\"\"\n",
    "    area_norm is box_area / image_area.\n",
    "    Rough depth bin: far, mid, near.\n",
    "    \"\"\"\n",
    "    if area_norm < 0.02:\n",
    "        return \"far\"\n",
    "    elif area_norm < 0.08:\n",
    "        return \"mid\"\n",
    "    else:\n",
    "        return \"near\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7edfaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13abcf0196fc4814970c4aacc44954f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing val images:   0%|          | 0/2098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>total_objs</th>\n",
       "      <th>count_channelization</th>\n",
       "      <th>frac_channelization</th>\n",
       "      <th>count_workers</th>\n",
       "      <th>frac_workers</th>\n",
       "      <th>count_vehicles</th>\n",
       "      <th>frac_vehicles</th>\n",
       "      <th>count_ttc_signs</th>\n",
       "      <th>...</th>\n",
       "      <th>channelization_left</th>\n",
       "      <th>workers_mid</th>\n",
       "      <th>channelization_mid</th>\n",
       "      <th>workers_right</th>\n",
       "      <th>channelization_right</th>\n",
       "      <th>workers_near</th>\n",
       "      <th>channelization_near</th>\n",
       "      <th>workers_far</th>\n",
       "      <th>channelization_far</th>\n",
       "      <th>scene_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>columbus_ed065d9b86d545b2af0042a058e7e907_0000...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>workzone_ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>columbus_ed065d9b86d545b2af0042a058e7e907_0000...</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>15</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>workzone_ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>columbus_ed065d9b86d545b2af0042a058e7e907_0000...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>workzone_ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>columbus_ed065d9b86d545b2af0042a058e7e907_0000...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>workzone_ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>columbus_ed065d9b86d545b2af0042a058e7e907_0000...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>workzone_ahead</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                          file_name  total_objs  \\\n",
       "0         1  columbus_ed065d9b86d545b2af0042a058e7e907_0000...          12   \n",
       "1         2  columbus_ed065d9b86d545b2af0042a058e7e907_0000...          21   \n",
       "2         3  columbus_ed065d9b86d545b2af0042a058e7e907_0000...           3   \n",
       "3         4  columbus_ed065d9b86d545b2af0042a058e7e907_0000...           7   \n",
       "4         5  columbus_ed065d9b86d545b2af0042a058e7e907_0000...           4   \n",
       "\n",
       "   count_channelization  frac_channelization  count_workers  frac_workers  \\\n",
       "0                     3             0.250000              0      0.000000   \n",
       "1                     5             0.238095             15      0.714286   \n",
       "2                     1             0.333333              0      0.000000   \n",
       "3                     1             0.142857              0      0.000000   \n",
       "4                     1             0.250000              0      0.000000   \n",
       "\n",
       "   count_vehicles  frac_vehicles  count_ttc_signs  ...  channelization_left  \\\n",
       "0               9       0.750000                0  ...                    0   \n",
       "1               1       0.047619                0  ...                    0   \n",
       "2               2       0.666667                0  ...                    0   \n",
       "3               6       0.857143                0  ...                    0   \n",
       "4               3       0.750000                0  ...                    0   \n",
       "\n",
       "   workers_mid  channelization_mid  workers_right  channelization_right  \\\n",
       "0            0                   0              0                     0   \n",
       "1            0                   0              8                     2   \n",
       "2            0                   1              0                     0   \n",
       "3            0                   0              0                     0   \n",
       "4            0                   0              0                     1   \n",
       "\n",
       "   workers_near  channelization_near  workers_far  channelization_far  \\\n",
       "0             0                    1            0                   2   \n",
       "1             0                    0           15                   5   \n",
       "2             0                    0            0                   0   \n",
       "3             0                    0            0                   1   \n",
       "4             0                    0            0                   1   \n",
       "\n",
       "      scene_label  \n",
       "0  workzone_ahead  \n",
       "1  workzone_ahead  \n",
       "2  workzone_ahead  \n",
       "3  workzone_ahead  \n",
       "4  workzone_ahead  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Run YOLO on each val image and build feature rows\n",
    "\n",
    "features = []\n",
    "\n",
    "for img_info in tqdm(coco_val[\"images\"], desc=\"Processing val images\"):\n",
    "    img_id = img_info[\"id\"]\n",
    "    file_name = img_info[\"file_name\"]\n",
    "    img_path = IMG_DIR / file_name\n",
    "\n",
    "    if not img_path.exists():\n",
    "        # if something is missing on disk, skip\n",
    "        continue\n",
    "\n",
    "    # run YOLO on this image\n",
    "    results = yolo_model.predict(\n",
    "        source=str(img_path),\n",
    "        imgsz=960,     # can change later if you want\n",
    "        conf=0.25,\n",
    "        iou=0.7,\n",
    "        verbose=False,\n",
    "        device=0,\n",
    "    )\n",
    "    r = results[0]\n",
    "\n",
    "    w = img_info[\"width\"]\n",
    "    h = img_info[\"height\"]\n",
    "    img_area = float(w * h)\n",
    "\n",
    "    if r.boxes is None or len(r.boxes) == 0:\n",
    "        # no detections, just zero features\n",
    "        row = {\n",
    "            \"image_id\": img_id,\n",
    "            \"file_name\": file_name,\n",
    "            \"total_objs\": 0,\n",
    "        }\n",
    "        for g in [\"channelization\", \"workers\", \"vehicles\", \"ttc_signs\", \"message_board\", \"other_roadwork\"]:\n",
    "            row[f\"count_{g}\"] = 0\n",
    "            row[f\"frac_{g}\"] = 0.0\n",
    "        for side in [\"left\", \"mid\", \"right\"]:\n",
    "            row[f\"workers_{side}\"] = 0\n",
    "            row[f\"channelization_{side}\"] = 0\n",
    "        for dist in [\"near\", \"mid\", \"far\"]:\n",
    "            row[f\"workers_{dist}\"] = 0\n",
    "            row[f\"channelization_{dist}\"] = 0\n",
    "        row[\"scene_label\"] = get_scene_label(img_info)\n",
    "        features.append(row)\n",
    "        continue\n",
    "\n",
    "    # there are detections\n",
    "    total_objs = 0\n",
    "    group_counts = Counter()\n",
    "    workers_side = Counter()\n",
    "    channel_side = Counter()\n",
    "    workers_dist = Counter()\n",
    "    channel_dist = Counter()\n",
    "\n",
    "    for box in r.boxes:\n",
    "        cls_id = int(box.cls.item())\n",
    "        # YOLO classes are 0 based, your COCO ids start at 1 and are in the same order\n",
    "        cat_name = cat_id_to_name.get(cls_id + 1, None)\n",
    "        if cat_name is None:\n",
    "            continue\n",
    "\n",
    "        group = name_to_group.get(cat_name, None)\n",
    "        if group is None:\n",
    "            group = \"other_roadwork\"\n",
    "\n",
    "        total_objs += 1\n",
    "        group_counts[group] += 1\n",
    "\n",
    "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "        cx = (x1 + x2) / 2.0\n",
    "        cy = (y1 + y2) / 2.0\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        x_norm = cx / w\n",
    "        area_norm = area / img_area\n",
    "\n",
    "        side = compute_position_bins(x_norm)\n",
    "        dist = area_bin(area_norm)\n",
    "\n",
    "        if group == \"workers\":\n",
    "            workers_side[side] += 1\n",
    "            workers_dist[dist] += 1\n",
    "        if group == \"channelization\":\n",
    "            channel_side[side] += 1\n",
    "            channel_dist[dist] += 1\n",
    "\n",
    "    row = {\n",
    "        \"image_id\": img_id,\n",
    "        \"file_name\": file_name,\n",
    "        \"total_objs\": total_objs,\n",
    "    }\n",
    "\n",
    "    for g in [\"channelization\", \"workers\", \"vehicles\", \"ttc_signs\", \"message_board\", \"other_roadwork\"]:\n",
    "        c = group_counts[g]\n",
    "        row[f\"count_{g}\"] = c\n",
    "        row[f\"frac_{g}\"] = c / total_objs if total_objs > 0 else 0.0\n",
    "\n",
    "    for side in [\"left\", \"mid\", \"right\"]:\n",
    "        row[f\"workers_{side}\"] = workers_side[side]\n",
    "        row[f\"channelization_{side}\"] = channel_side[side]\n",
    "\n",
    "    for dist in [\"near\", \"mid\", \"far\"]:\n",
    "        row[f\"workers_{dist}\"] = workers_dist[dist]\n",
    "        row[f\"channelization_{dist}\"] = channel_dist[dist]\n",
    "\n",
    "    row[\"scene_label\"] = get_scene_label(img_info)\n",
    "\n",
    "    features.append(row)\n",
    "\n",
    "# build DataFrame\n",
    "df_features = pd.DataFrame(features)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ee96ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature table shape: (2098, 26)\n",
      "Scene label distribution:\n",
      "scene_label\n",
      "workzone_ahead    2041\n",
      "lane_shift          56\n",
      "None                 1\n",
      "Name: count, dtype: int64\n",
      "                       count         mean         std  min     25%  \\\n",
      "image_id              2098.0  1049.500000  605.784753  1.0  525.25   \n",
      "total_objs            2098.0     6.897045    4.846315  0.0    3.00   \n",
      "count_channelization  2098.0     3.557197    3.566096  0.0    1.00   \n",
      "frac_channelization   2098.0     0.518858    0.340018  0.0    0.25   \n",
      "count_workers         2098.0     2.629647    3.324827  0.0    0.00   \n",
      "frac_workers          2098.0     0.351062    0.334336  0.0    0.00   \n",
      "count_vehicles        2098.0     0.710200    1.888625  0.0    0.00   \n",
      "frac_vehicles         2098.0     0.102434    0.235005  0.0    0.00   \n",
      "count_ttc_signs       2098.0     0.000000    0.000000  0.0    0.00   \n",
      "frac_ttc_signs        2098.0     0.000000    0.000000  0.0    0.00   \n",
      "count_message_board   2098.0     0.000000    0.000000  0.0    0.00   \n",
      "frac_message_board    2098.0     0.000000    0.000000  0.0    0.00   \n",
      "count_other_roadwork  2098.0     0.000000    0.000000  0.0    0.00   \n",
      "frac_other_roadwork   2098.0     0.000000    0.000000  0.0    0.00   \n",
      "workers_left          2098.0     0.619161    1.466964  0.0    0.00   \n",
      "channelization_left   2098.0     0.840324    1.460252  0.0    0.00   \n",
      "workers_mid           2098.0     0.000953    0.030868  0.0    0.00   \n",
      "channelization_mid    2098.0     0.444233    0.689168  0.0    0.00   \n",
      "workers_right         2098.0     0.761678    1.595302  0.0    0.00   \n",
      "channelization_right  2098.0     1.119161    1.731116  0.0    0.00   \n",
      "\n",
      "                              50%          75%     max  \n",
      "image_id              1049.500000  1573.750000  2098.0  \n",
      "total_objs               6.000000     9.000000    42.0  \n",
      "count_channelization     2.000000     5.000000    23.0  \n",
      "frac_channelization      0.500000     0.833333     1.0  \n",
      "count_workers            2.000000     4.000000    29.0  \n",
      "frac_workers             0.333333     0.666667     1.0  \n",
      "count_vehicles           0.000000     0.000000    26.0  \n",
      "frac_vehicles            0.000000     0.000000     1.0  \n",
      "count_ttc_signs          0.000000     0.000000     0.0  \n",
      "frac_ttc_signs           0.000000     0.000000     0.0  \n",
      "count_message_board      0.000000     0.000000     0.0  \n",
      "frac_message_board       0.000000     0.000000     0.0  \n",
      "count_other_roadwork     0.000000     0.000000     0.0  \n",
      "frac_other_roadwork      0.000000     0.000000     0.0  \n",
      "workers_left             0.000000     0.750000    15.0  \n",
      "channelization_left      0.000000     1.000000    12.0  \n",
      "workers_mid              0.000000     0.000000     1.0  \n",
      "channelization_mid       0.000000     1.000000     5.0  \n",
      "workers_right            0.000000     1.000000    15.0  \n",
      "channelization_right     1.000000     2.000000    16.0  \n",
      "Saved features to: models/scene_features_val_from_yolo.csv\n"
     ]
    }
   ],
   "source": [
    "# 8. Sanity checks and save CSV\n",
    "\n",
    "print(\"Feature table shape:\", df_features.shape)\n",
    "print(\"Scene label distribution:\")\n",
    "print(df_features[\"scene_label\"].value_counts(dropna=False))\n",
    "\n",
    "print(df_features.describe().T.head(20))\n",
    "\n",
    "OUT_PATH = Path(\"models\") / \"scene_features_val_from_yolo.csv\"\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_features.to_csv(OUT_PATH, index=False)\n",
    "print(\"Saved features to:\", OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de1c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class map from model:\n",
      "{0: 'Police Officer', 1: 'Police Vehicle', 2: 'Cone', 3: 'Fence', 4: 'Drum', 5: 'Barricade', 6: 'Barrier', 7: 'Work Vehicle', 8: 'Vertical Panel', 9: 'Tubular Marker', 10: 'Arrow Board', 11: 'Bike Lane', 12: 'Work Equipment', 13: 'Worker', 14: 'Other Roadwork Objects', 15: 'Temporary Traffic Control Message Board', 16: 'Temporary Traffic Control Sign', 17: 'Temporary Traffic Control Sign: left arrow', 18: 'Temporary Traffic Control Sign: right arrow', 19: 'Temporary Traffic Control Sign: up arrow', 20: 'Temporary Traffic Control Sign: left chevron', 21: 'Temporary Traffic Control Sign: right lane ends sign', 22: 'Temporary Traffic Control Sign: two lane shift arrows', 23: 'Temporary Traffic Control Sign: right chevron', 24: 'Temporary Traffic Control Sign: lane shift arrow', 25: 'Temporary Traffic Control Sign: up diagonal right arrow', 26: 'Temporary Traffic Control Sign: left lane ends sign', 27: 'Temporary Traffic Control Sign: bent left arrow', 28: 'Temporary Traffic Control Sign: flagger', 29: 'Temporary Traffic Control Sign: bent right arrow', 30: 'Temporary Traffic Control Sign: no left turn', 31: 'Temporary Traffic Control Sign: pedestrian: right arrow', 32: 'Temporary Traffic Control Sign: pedestrian: left arrow', 33: 'Temporary Traffic Control Sign: up diagonal left arrow', 34: 'Temporary Traffic Control Sign: pedestrian', 35: 'Temporary Traffic Control Sign: no right turn', 36: 'Temporary Traffic Control Sign: bi-directional arrow', 37: 'Temporary Traffic Control Sign: two upward diagonal arrows', 38: 'Temporary Traffic Control Sign: curved right arrow', 39: 'Temporary Traffic Control Sign: down diagonal left arrow', 40: 'Temporary Traffic Control Sign: do not enter sign', 41: 'Temporary Traffic Control Sign: worker', 42: 'Temporary Traffic Control Sign: bicycle', 43: 'Temporary Traffic Control Sign: two downward diagonal arrows', 44: 'Temporary Traffic Control Sign: curved left arrow', 45: 'Temporary Traffic Control Sign: curved left arrow, curved right arrow', 46: 'Temporary Traffic Control Sign: work vehicle', 47: 'Temporary Traffic Control Sign: traffic signal', 48: 'Temporary Traffic Control Sign: up arrow, stop sign'}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "YOLO_MODEL_PATH = \"workzone-yolo-v12/experiment-1/weights/best.pt\"  # adjust if needed\n",
    "IMG_DIR = Path(\"data/images\")  # same as before\n",
    "\n",
    "model = YOLO(YOLO_MODEL_PATH)\n",
    "print(\"Class map from model:\")\n",
    "print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f2557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "ANN_DIR = DATA_DIR / \"annotations\"\n",
    "IMG_DIR = DATA_DIR / \"images\"\n",
    "\n",
    "TRAIN_JSON = ANN_DIR / \"instances_train_gps_split_with_signs.json\"\n",
    "VAL_JSON   = ANN_DIR / \"instances_val_gps_split_with_signs.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a90a66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5318, 2098)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_coco(path: Path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def build_img_and_anns(coco):\n",
    "    imgs = {img[\"id\"]: img for img in coco[\"images\"]}\n",
    "    anns_by_img = {img_id: [] for img_id in imgs.keys()}\n",
    "    for ann in coco[\"annotations\"]:\n",
    "        anns_by_img[ann[\"image_id\"]].append(ann)\n",
    "    return imgs, anns_by_img\n",
    "\n",
    "coco_train = load_coco(TRAIN_JSON)\n",
    "coco_val   = load_coco(VAL_JSON)\n",
    "\n",
    "train_imgs, train_anns = build_img_and_anns(coco_train)\n",
    "val_imgs,   val_anns   = build_img_and_anns(coco_val)\n",
    "\n",
    "len(train_imgs), len(val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "841aa967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene_label\n",
      "lane_shift    238\n",
      "Name: count, dtype: int64\n",
      "scene_label\n",
      "lane_shift    56\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_scene_label(img_dict):\n",
    "    tags = img_dict.get(\"scene_level_tags\", {})\n",
    "    travel_alteration = tags.get(\"travel_alteration\", [])\n",
    "\n",
    "    if isinstance(travel_alteration, list):\n",
    "        travel_alteration = travel_alteration[0] if travel_alteration else None\n",
    "\n",
    "    if travel_alteration is None:\n",
    "        return None\n",
    "\n",
    "    txt = str(travel_alteration).lower()\n",
    "\n",
    "    if \"lane shift\" in txt:\n",
    "        return \"lane_shift\"\n",
    "    if \"workzone ahead\" in txt or \"work zone ahead\" in txt:\n",
    "        return \"workzone_ahead\"\n",
    "\n",
    "    return None\n",
    "\n",
    "def build_scene_df(imgs_dict, split_name):\n",
    "    rows = []\n",
    "    for img_id, img in imgs_dict.items():\n",
    "        label = get_scene_label(img)\n",
    "        if label is None:\n",
    "            continue\n",
    "        rows.append(\n",
    "            {\n",
    "                \"image_id\": img_id,\n",
    "                \"file_name\": img[\"file_name\"],\n",
    "                \"scene_label\": label,\n",
    "                \"split\": split_name,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_train = build_scene_df(train_imgs, \"train\")\n",
    "df_val   = build_scene_df(val_imgs, \"val\")\n",
    "\n",
    "print(df_train[\"scene_label\"].value_counts())\n",
    "print(df_val[\"scene_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba7e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238, 5) (56, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>scene_label</th>\n",
       "      <th>split</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129</td>\n",
       "      <td>boston_e8b7c866e5734e8b898ea791643bf1d8_000003...</td>\n",
       "      <td>lane_shift</td>\n",
       "      <td>val</td>\n",
       "      <td>data/images/boston_e8b7c866e5734e8b898ea791643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>boston_e8b7c866e5734e8b898ea791643bf1d8_000003...</td>\n",
       "      <td>lane_shift</td>\n",
       "      <td>val</td>\n",
       "      <td>data/images/boston_e8b7c866e5734e8b898ea791643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>boston_e8b7c866e5734e8b898ea791643bf1d8_000003...</td>\n",
       "      <td>lane_shift</td>\n",
       "      <td>val</td>\n",
       "      <td>data/images/boston_e8b7c866e5734e8b898ea791643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185</td>\n",
       "      <td>boston_d7d96e38384140d89a8cb3c42c84dbea_000002...</td>\n",
       "      <td>lane_shift</td>\n",
       "      <td>val</td>\n",
       "      <td>data/images/boston_d7d96e38384140d89a8cb3c42c8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186</td>\n",
       "      <td>boston_d7d96e38384140d89a8cb3c42c84dbea_000002...</td>\n",
       "      <td>lane_shift</td>\n",
       "      <td>val</td>\n",
       "      <td>data/images/boston_d7d96e38384140d89a8cb3c42c8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                          file_name scene_label  \\\n",
       "0       129  boston_e8b7c866e5734e8b898ea791643bf1d8_000003...  lane_shift   \n",
       "1       131  boston_e8b7c866e5734e8b898ea791643bf1d8_000003...  lane_shift   \n",
       "2       132  boston_e8b7c866e5734e8b898ea791643bf1d8_000003...  lane_shift   \n",
       "3       185  boston_d7d96e38384140d89a8cb3c42c84dbea_000002...  lane_shift   \n",
       "4       186  boston_d7d96e38384140d89a8cb3c42c84dbea_000002...  lane_shift   \n",
       "\n",
       "  split                                           img_path  \n",
       "0   val  data/images/boston_e8b7c866e5734e8b898ea791643...  \n",
       "1   val  data/images/boston_e8b7c866e5734e8b898ea791643...  \n",
       "2   val  data/images/boston_e8b7c866e5734e8b898ea791643...  \n",
       "3   val  data/images/boston_d7d96e38384140d89a8cb3c42c8...  \n",
       "4   val  data/images/boston_d7d96e38384140d89a8cb3c42c8...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_image_path(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"img_path\"] = df[\"file_name\"].apply(lambda fn: IMG_DIR / fn)\n",
    "    exists_mask = df[\"img_path\"].apply(lambda p: p.exists())\n",
    "    missing = (~exists_mask).sum()\n",
    "    if missing > 0:\n",
    "        print(f\"Warning: {missing} images not found on disk, dropping them.\")\n",
    "    return df[exists_mask].reset_index(drop=True)\n",
    "\n",
    "df_train = add_image_path(df_train)\n",
    "df_val   = add_image_path(df_val)\n",
    "\n",
    "print(df_train.shape, df_val.shape)\n",
    "df_val.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa18633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Police Officer', 1: 'Police Vehicle', 2: 'Cone', 3: 'Fence', 4: 'Drum', 5: 'Barricade', 6: 'Barrier', 7: 'Work Vehicle', 8: 'Vertical Panel', 9: 'Tubular Marker', 10: 'Arrow Board', 11: 'Bike Lane', 12: 'Work Equipment', 13: 'Worker', 14: 'Other Roadwork Objects', 15: 'Temporary Traffic Control Message Board', 16: 'Temporary Traffic Control Sign', 17: 'Temporary Traffic Control Sign: left arrow', 18: 'Temporary Traffic Control Sign: right arrow', 19: 'Temporary Traffic Control Sign: up arrow', 20: 'Temporary Traffic Control Sign: left chevron', 21: 'Temporary Traffic Control Sign: right lane ends sign', 22: 'Temporary Traffic Control Sign: two lane shift arrows', 23: 'Temporary Traffic Control Sign: right chevron', 24: 'Temporary Traffic Control Sign: lane shift arrow', 25: 'Temporary Traffic Control Sign: up diagonal right arrow', 26: 'Temporary Traffic Control Sign: left lane ends sign', 27: 'Temporary Traffic Control Sign: bent left arrow', 28: 'Temporary Traffic Control Sign: flagger', 29: 'Temporary Traffic Control Sign: bent right arrow', 30: 'Temporary Traffic Control Sign: no left turn', 31: 'Temporary Traffic Control Sign: pedestrian: right arrow', 32: 'Temporary Traffic Control Sign: pedestrian: left arrow', 33: 'Temporary Traffic Control Sign: up diagonal left arrow', 34: 'Temporary Traffic Control Sign: pedestrian', 35: 'Temporary Traffic Control Sign: no right turn', 36: 'Temporary Traffic Control Sign: bi-directional arrow', 37: 'Temporary Traffic Control Sign: two upward diagonal arrows', 38: 'Temporary Traffic Control Sign: curved right arrow', 39: 'Temporary Traffic Control Sign: down diagonal left arrow', 40: 'Temporary Traffic Control Sign: do not enter sign', 41: 'Temporary Traffic Control Sign: worker', 42: 'Temporary Traffic Control Sign: bicycle', 43: 'Temporary Traffic Control Sign: two downward diagonal arrows', 44: 'Temporary Traffic Control Sign: curved left arrow', 45: 'Temporary Traffic Control Sign: curved left arrow, curved right arrow', 46: 'Temporary Traffic Control Sign: work vehicle', 47: 'Temporary Traffic Control Sign: traffic signal', 48: 'Temporary Traffic Control Sign: up arrow, stop sign'}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "YOLO_MODEL_PATH = \"workzone-yolo-v12/experiment-1/weights/best.pt\"  # adjust if needed\n",
    "model = YOLO(YOLO_MODEL_PATH)\n",
    "print(model.names)\n",
    "\n",
    "def inspect_image_predictions(row, conf=0.25, iou=0.7):\n",
    "    img_path = row[\"img_path\"]\n",
    "    print(f\"\\nImage id={row['image_id']}  file={row['file_name']}\")\n",
    "    print(f\"Path: {img_path}\")\n",
    "\n",
    "    results = model.predict(\n",
    "        source=str(img_path),\n",
    "        conf=conf,\n",
    "        iou=iou,\n",
    "        verbose=False,\n",
    "        device=0\n",
    "    )\n",
    "    r = results[0]\n",
    "\n",
    "    if r.boxes is None or len(r.boxes) == 0:\n",
    "        print(\"No detections\")\n",
    "        return\n",
    "\n",
    "    cls = r.boxes.cls.cpu().numpy().astype(int)\n",
    "    confs = r.boxes.conf.cpu().numpy()\n",
    "    xyxy = r.boxes.xyxy.cpu().numpy()\n",
    "\n",
    "    for cid, c, box in zip(cls, confs, xyxy):\n",
    "        name = model.names.get(int(cid), f\"class_{cid}\")\n",
    "        x1, y1, x2, y2 = box\n",
    "        print(f\"  {name:45s}  conf={c:.3f}  box=({x1:.1f},{y1:.1f},{x2:.1f},{y2:.1f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4256251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image id=1915  file=denver_ebad84687fa141e2abe66a65753da0ac_000002_14640.jpg\n",
      "Path: data/images/denver_ebad84687fa141e2abe66a65753da0ac_000002_14640.jpg\n",
      "  Work Vehicle                                   conf=0.956  box=(472.0,419.6,754.3,814.8)\n",
      "  Police Officer                                 conf=0.901  box=(278.7,748.8,383.9,950.3)\n",
      "  Police Officer                                 conf=0.870  box=(750.3,692.4,795.4,798.9)\n",
      "  Police Officer                                 conf=0.842  box=(871.9,673.0,902.6,742.0)\n",
      "  Police Officer                                 conf=0.725  box=(753.4,648.0,771.9,688.6)\n",
      "  Police Officer                                 conf=0.664  box=(865.9,648.8,880.2,686.8)\n",
      "  Police Officer                                 conf=0.599  box=(653.9,648.6,670.3,687.9)\n",
      "  Police Officer                                 conf=0.550  box=(567.1,669.5,586.2,720.1)\n",
      "  Barricade                                      conf=0.468  box=(696.6,622.1,791.6,685.8)\n",
      "  Barricade                                      conf=0.436  box=(779.9,600.7,883.9,679.7)\n",
      "  Barrier                                        conf=0.386  box=(788.7,622.1,812.8,679.7)\n",
      "  Tubular Marker                                 conf=0.355  box=(741.2,605.3,762.2,627.5)\n",
      "\n",
      "Image id=1319  file=los_angeles_cca14054afbb44ddadfd2b1a157f2d70_000001_03540.jpg\n",
      "Path: data/images/los_angeles_cca14054afbb44ddadfd2b1a157f2d70_000001_03540.jpg\n",
      "  Work Vehicle                                   conf=0.865  box=(1022.5,584.6,1073.7,657.8)\n",
      "  Police Officer                                 conf=0.755  box=(1302.9,689.5,1327.6,731.9)\n",
      "  Police Officer                                 conf=0.641  box=(1201.5,669.5,1221.7,707.3)\n",
      "  Police Officer                                 conf=0.503  box=(1043.7,644.8,1054.6,664.8)\n",
      "  Police Officer                                 conf=0.409  box=(1065.9,648.3,1077.8,672.7)\n",
      "  Police Officer                                 conf=0.392  box=(1141.2,665.1,1157.0,692.7)\n",
      "  Tubular Marker                                 conf=0.367  box=(751.2,582.6,765.3,601.0)\n",
      "  Police Officer                                 conf=0.265  box=(1094.7,654.7,1111.1,681.5)\n",
      "\n",
      "Image id=1362  file=los_angeles_cc06242ad34a4b7189788da71540ffeb_000000_13680.jpg\n",
      "Path: data/images/los_angeles_cc06242ad34a4b7189788da71540ffeb_000000_13680.jpg\n",
      "  Tubular Marker                                 conf=0.871  box=(1144.9,623.4,1227.7,699.3)\n",
      "  Police Officer                                 conf=0.736  box=(1234.5,646.2,1267.3,701.8)\n",
      "  Cone                                           conf=0.645  box=(1015.9,595.7,1052.8,657.0)\n",
      "  Cone                                           conf=0.474  box=(1060.2,589.7,1132.0,683.3)\n",
      "  Cone                                           conf=0.321  box=(1003.2,577.7,1032.7,607.2)\n",
      "  Police Officer                                 conf=0.264  box=(973.3,589.9,985.2,616.6)\n",
      "\n",
      "Image id=1221  file=pittsburgh_37d14e2f6c77464dbc10c7fb83a17a2d_000001_01590.jpg\n",
      "Path: data/images/pittsburgh_37d14e2f6c77464dbc10c7fb83a17a2d_000001_01590.jpg\n",
      "  Barricade                                      conf=0.927  box=(1023.5,170.6,1280.1,744.3)\n",
      "  Police Officer                                 conf=0.920  box=(1431.2,799.2,1529.0,964.6)\n",
      "  Cone                                           conf=0.898  box=(907.2,660.0,960.4,757.8)\n",
      "  Police Officer                                 conf=0.858  box=(1488.0,682.4,1527.4,741.5)\n",
      "  Police Officer                                 conf=0.831  box=(1807.8,674.0,1853.6,752.1)\n",
      "  Police Officer                                 conf=0.789  box=(1345.1,702.2,1373.3,745.7)\n",
      "  Police Officer                                 conf=0.768  box=(960.2,686.4,978.5,717.5)\n",
      "  Police Officer                                 conf=0.555  box=(1847.8,669.2,1894.4,736.4)\n",
      "  Police Officer                                 conf=0.425  box=(976.4,667.7,988.0,693.6)\n",
      "  Cone                                           conf=0.350  box=(871.5,614.3,904.6,647.8)\n",
      "  Police Officer                                 conf=0.250  box=(990.4,658.7,1002.7,686.2)\n",
      "\n",
      "Image id=500  file=boston_042e1caf93114d3286c11ba14ddaa759_000001_03510.jpg\n",
      "Path: data/images/boston_042e1caf93114d3286c11ba14ddaa759_000001_03510.jpg\n",
      "  Tubular Marker                                 conf=0.932  box=(1241.3,623.4,1333.7,713.8)\n",
      "  Tubular Marker                                 conf=0.869  box=(1403.8,488.1,1457.1,539.2)\n",
      "  Police Officer                                 conf=0.835  box=(1203.9,687.1,1232.1,738.9)\n",
      "  Police Officer                                 conf=0.784  box=(1149.1,682.9,1172.7,728.2)\n",
      "  Police Officer                                 conf=0.774  box=(1136.6,680.1,1155.6,721.0)\n",
      "  Police Officer                                 conf=0.760  box=(1119.1,679.4,1138.2,715.1)\n",
      "  Police Officer                                 conf=0.753  box=(1105.8,674.4,1121.1,707.2)\n",
      "  Barricade                                      conf=0.687  box=(1215.7,564.8,1379.0,708.2)\n",
      "  Police Officer                                 conf=0.624  box=(1085.7,669.3,1100.2,699.0)\n",
      "  Police Officer                                 conf=0.520  box=(1136.8,661.7,1148.0,688.8)\n",
      "  Police Officer                                 conf=0.453  box=(1097.1,669.0,1110.3,700.5)\n",
      "  Police Officer                                 conf=0.375  box=(1177.9,660.0,1190.5,690.1)\n",
      "  Police Officer                                 conf=0.270  box=(1118.2,664.1,1130.7,688.8)\n",
      "\n",
      "Image id=132  file=boston_e8b7c866e5734e8b898ea791643bf1d8_000003_00660.jpg\n",
      "Path: data/images/boston_e8b7c866e5734e8b898ea791643bf1d8_000003_00660.jpg\n",
      "  Barrier                                        conf=0.897  box=(1303.8,538.3,1475.6,883.8)\n",
      "  Barrier                                        conf=0.854  box=(1667.7,562.8,1705.4,674.1)\n",
      "  Barrier                                        conf=0.816  box=(1625.3,587.5,1681.9,684.5)\n",
      "  Barrier                                        conf=0.748  box=(1809.1,552.7,1864.9,697.9)\n",
      "  Barricade                                      conf=0.645  box=(1146.6,476.9,1578.0,705.6)\n",
      "  Cone                                           conf=0.580  box=(1531.5,615.6,1624.7,723.5)\n",
      "  Barrier                                        conf=0.381  box=(1165.5,561.2,1223.8,750.1)\n",
      "  Barrier                                        conf=0.338  box=(1635.3,570.6,1703.5,683.9)\n",
      "\n",
      "Image id=1315  file=los_angeles_cca14054afbb44ddadfd2b1a157f2d70_000001_04410.jpg\n",
      "Path: data/images/los_angeles_cca14054afbb44ddadfd2b1a157f2d70_000001_04410.jpg\n",
      "  Police Officer                                 conf=0.829  box=(1437.1,735.2,1473.8,793.8)\n",
      "  Police Officer                                 conf=0.816  box=(1321.8,708.8,1353.0,761.3)\n",
      "  Police Officer                                 conf=0.808  box=(1235.4,695.4,1260.2,738.0)\n",
      "  Police Officer                                 conf=0.708  box=(1176.3,681.1,1198.3,720.0)\n",
      "  Barricade                                      conf=0.677  box=(1073.6,597.7,1241.1,693.7)\n",
      "  Police Officer                                 conf=0.677  box=(1058.6,657.5,1074.4,689.7)\n",
      "  Police Officer                                 conf=0.668  box=(1133.2,671.1,1153.9,709.2)\n",
      "  Barrier                                        conf=0.613  box=(1109.1,618.2,1145.2,705.0)\n",
      "  Police Officer                                 conf=0.578  box=(1086.9,668.0,1105.3,698.7)\n",
      "  Barricade                                      conf=0.530  box=(1031.4,572.7,1084.4,657.4)\n",
      "  Barrier                                        conf=0.504  box=(1236.3,624.0,1266.3,705.1)\n",
      "  Police Officer                                 conf=0.298  box=(1040.9,652.6,1050.0,674.6)\n",
      "\n",
      "Image id=1893  file=detroit_6fd9c1f2f80c483484beb8ffac7bd4bb_000000_08730.jpg\n",
      "Path: data/images/detroit_6fd9c1f2f80c483484beb8ffac7bd4bb_000000_08730.jpg\n",
      "  Work Vehicle                                   conf=0.938  box=(1759.9,366.7,1919.7,1022.0)\n",
      "  Police Vehicle                                 conf=0.920  box=(1430.2,755.9,1536.9,876.0)\n",
      "  Police Vehicle                                 conf=0.876  box=(1344.7,728.4,1395.9,791.5)\n",
      "  Police Vehicle                                 conf=0.869  box=(1393.6,729.4,1451.1,796.6)\n",
      "  Police Vehicle                                 conf=0.829  box=(1289.6,723.7,1335.5,780.6)\n",
      "  Barricade                                      conf=0.817  box=(1188.6,249.9,1386.4,705.8)\n",
      "  Police Vehicle                                 conf=0.744  box=(1248.8,716.6,1279.7,758.0)\n",
      "  Barricade                                      conf=0.715  box=(1252.0,663.1,1299.6,705.3)\n",
      "  Police Vehicle                                 conf=0.695  box=(1225.1,712.1,1244.8,746.2)\n",
      "  Police Vehicle                                 conf=0.276  box=(1393.9,710.2,1406.7,731.9)\n",
      "\n",
      "Image id=1916  file=denver_ebad84687fa141e2abe66a65753da0ac_000002_14610.jpg\n",
      "Path: data/images/denver_ebad84687fa141e2abe66a65753da0ac_000002_14610.jpg\n",
      "  Work Vehicle                                   conf=0.954  box=(608.5,470.7,822.7,771.3)\n",
      "  Police Officer                                 conf=0.882  box=(73.5,763.8,196.0,986.0)\n",
      "  Police Officer                                 conf=0.880  box=(559.3,707.4,616.7,834.9)\n",
      "  Police Officer                                 conf=0.811  box=(818.7,678.2,852.7,759.6)\n",
      "  Police Officer                                 conf=0.635  box=(138.1,642.7,151.6,677.5)\n",
      "  Barrier                                        conf=0.630  box=(1437.8,618.4,1468.0,694.6)\n",
      "  Police Officer                                 conf=0.627  box=(882.9,650.1,896.4,681.5)\n",
      "  Police Officer                                 conf=0.614  box=(636.2,654.8,653.1,701.5)\n",
      "  Barricade                                      conf=0.480  box=(721.2,607.6,799.1,678.8)\n",
      "  Barricade                                      conf=0.414  box=(573.1,606.0,706.5,689.3)\n",
      "  Barrier                                        conf=0.383  box=(807.5,622.3,828.5,676.6)\n",
      "  Barrier                                        conf=0.291  box=(849.2,635.8,876.4,676.1)\n",
      "\n",
      "Image id=1313  file=los_angeles_cca14054afbb44ddadfd2b1a157f2d70_000001_04470.jpg\n",
      "Path: data/images/los_angeles_cca14054afbb44ddadfd2b1a157f2d70_000001_04470.jpg\n",
      "  Police Officer                                 conf=0.872  box=(1432.8,755.2,1490.4,850.1)\n",
      "  Police Officer                                 conf=0.841  box=(1702.0,816.2,1785.0,951.8)\n",
      "  Barrier                                        conf=0.798  box=(1231.3,614.2,1309.6,783.3)\n",
      "  Barricade                                      conf=0.755  box=(1039.5,573.5,1090.8,654.7)\n",
      "  Barricade                                      conf=0.644  box=(1098.5,585.3,1247.1,722.2)\n",
      "  Barrier                                        conf=0.630  box=(1396.3,625.2,1439.9,742.4)\n",
      "  Police Officer                                 conf=0.341  box=(1305.0,728.9,1351.0,809.2)\n",
      "  Barricade                                      conf=0.310  box=(1100.0,587.3,1217.2,696.7)\n",
      "  Police Officer                                 conf=0.296  box=(1043.2,651.1,1056.8,675.9)\n",
      "  Police Officer                                 conf=0.259  box=(1083.0,669.3,1104.3,708.9)\n"
     ]
    }
   ],
   "source": [
    "# Pick some random val images\n",
    "sample_rows = df_val.sample(10, random_state=0)\n",
    "\n",
    "for _, row in sample_rows.iterrows():\n",
    "    inspect_image_predictions(row, conf=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c3302a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 val images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc81a2d10834c3f9997bc432fc7128f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning val detections:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 253, 5: 81, 4: 69, 6: 41, 2: 38, 9: 29, 1: 25, 7: 23, 3: 15, 8: 4})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from ultralytics import YOLO\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "YOLO_MODEL_PATH = \"workzone-yolo-v12/experiment-1/weights/best.pt\"  # adjust if needed\n",
    "model = YOLO(YOLO_MODEL_PATH)\n",
    "\n",
    "# make sure df_val exists and has 'img_path'\n",
    "print(len(df_val), \"val images\")\n",
    "\n",
    "det_counts = Counter()\n",
    "conf_thr = 0.15  # lower conf to catch rare TTC signs\n",
    "\n",
    "for _, row in tqdm(df_val.iterrows(), total=len(df_val), desc=\"Scanning val detections\"):\n",
    "    img_path = row[\"img_path\"]\n",
    "    results = model.predict(\n",
    "        source=str(img_path),\n",
    "        conf=conf_thr,\n",
    "        iou=0.7,\n",
    "        verbose=False,\n",
    "        device=0,\n",
    "    )\n",
    "    r = results[0]\n",
    "    if r.boxes is None or len(r.boxes) == 0:\n",
    "        continue\n",
    "    cls_ids = r.boxes.cls.cpu().numpy().astype(int)\n",
    "    for cid in cls_ids:\n",
    "        det_counts[int(cid)] += 1\n",
    "\n",
    "det_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d82c6beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.232  Python-3.12.3 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti Laptop GPU, 12227MiB)\n",
      "YOLOv12s summary (fused): 159 layers, 9,249,843 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 230.936.2 MB/s, size: 670.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/wesley/code/workzone/workzone_yolo/labels/val.cache... 2046 images, 0 backgrounds, 0 corrupt: 100%  2046/2046 1.0Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_1313e092c4d94bdf8349c99f763354b4_000000_07230.jpg: 14 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_1313e092c4d94bdf8349c99f763354b4_000000_07410.jpg: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_1313e092c4d94bdf8349c99f763354b4_000000_08220.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_1313e092c4d94bdf8349c99f763354b4_000001_08160.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_3c5d946bb34d48649217ba001b874b17_000000_07530.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_3c5d946bb34d48649217ba001b874b17_000000_13830.jpg: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_3c5d946bb34d48649217ba001b874b17_000001_02610.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_3c5d946bb34d48649217ba001b874b17_000003_00570.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_43adb415eb0244ac8c5012fe05c623ba_000000_10710.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_43adb415eb0244ac8c5012fe05c623ba_000000_10830.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_72bd145a61e04b9c8d774dafe2c39f2f_000001_08040.jpg: 21 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_754820fa4bc34fd798a8b1541dd1fb7a_000001_07350.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_754820fa4bc34fd798a8b1541dd1fb7a_000001_07590.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_754820fa4bc34fd798a8b1541dd1fb7a_000001_14010.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_754820fa4bc34fd798a8b1541dd1fb7a_000002_01140.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_754820fa4bc34fd798a8b1541dd1fb7a_000002_19020.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03000.jpg: 11 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03060.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03150.jpg: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03210.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03720.jpg: 11 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03900.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_90d6cd5a073c411f82436941ad1372fc_000000_21930.jpg: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_b0e38fe839374b7e90fe124e4cc4b5f0_000001_20640.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_b0e38fe839374b7e90fe124e4cc4b5f0_000002_03810.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_b0e38fe839374b7e90fe124e4cc4b5f0_000002_05250.jpg: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_b0e38fe839374b7e90fe124e4cc4b5f0_000002_05610.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000000_02790.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000000_08700.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000000_08820.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000002_06030.jpg: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000002_23880.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000003_00210.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000001_18270.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000001_20790.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000002_00210.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000003_09240.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000003_17340.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000003_17430.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000003_17640.jpg: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000004_01020.jpg: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000004_01140.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000004_02790.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000005_20850.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000006_00360.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000006_01020.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1af570d029aa48378193e82a5e76125e_000000_22950.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1b840ba13539483cac9db9f30a6047f6_000003_21150.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1b840ba13539483cac9db9f30a6047f6_000003_22740.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_4240703ce3874dae8354b9f7fb20e04f_000001_11040.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_4240703ce3874dae8354b9f7fb20e04f_000002_20070.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_61c8420d09504d4a83e0946aa5491e44_000000_02430.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_61c8420d09504d4a83e0946aa5491e44_000000_02550.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_61c8420d09504d4a83e0946aa5491e44_000002_15990.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_66223187eea64275b1b9cc48ec18b808_000001_02610.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_66223187eea64275b1b9cc48ec18b808_000001_02700.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_66223187eea64275b1b9cc48ec18b808_000001_05130.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_66223187eea64275b1b9cc48ec18b808_000001_07830.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_6921f42ed03d45d2a20d1dee1ea9a9fc_000000_15360.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_6921f42ed03d45d2a20d1dee1ea9a9fc_000010_18180.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_6921f42ed03d45d2a20d1dee1ea9a9fc_000010_20100.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_8037fa57ddee41779b558f7d72d7d7fd_000002_07980.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_8037fa57ddee41779b558f7d72d7d7fd_000003_03390.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_8037fa57ddee41779b558f7d72d7d7fd_000003_04620.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_8037fa57ddee41779b558f7d72d7d7fd_000003_07560.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_828ed3aacd9442cf922819cdee32dbe4_000000_00240.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_828ed3aacd9442cf922819cdee32dbe4_000000_18090.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_828ed3aacd9442cf922819cdee32dbe4_000002_05130.jpg: 8 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%  128/128 3.0it/s 42.1s0.3ss\n",
      "                   all       2046      15890      0.741      0.587      0.687      0.499\n",
      "        Police Officer       1301       5396      0.795      0.729      0.785      0.559\n",
      "        Police Vehicle        440       1470      0.851       0.72      0.822      0.539\n",
      "                  Cone        579       1396      0.774      0.566      0.697      0.452\n",
      "                 Fence        480       1031      0.607      0.463      0.534      0.413\n",
      "                  Drum        240       1606      0.884      0.625      0.779      0.529\n",
      "             Barricade       1283       2408      0.663       0.57      0.619      0.433\n",
      "               Barrier        545       1221       0.73        0.5      0.626       0.41\n",
      "          Work Vehicle        158        161       0.78      0.683      0.787      0.678\n",
      "        Vertical Panel         69         70      0.604      0.529      0.592      0.464\n",
      "        Tubular Marker        677       1131      0.719      0.483      0.626      0.508\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Saving /home/wesley/code/workzone/runs/detect/val6/predictions.json...\n",
      "Results saved to \u001b[1m/home/wesley/code/workzone/runs/detect/val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "YOLO_MODEL_PATH = \"workzone-yolo-v12/experiment-1/weights/best.pt\"  # adjust if needed\n",
    "model = YOLO(YOLO_MODEL_PATH)\n",
    "\n",
    "results = model.val(\n",
    "    data=\"workzone_yolo/workzone_yolo.yaml\",\n",
    "    imgsz=960,\n",
    "    conf=0.25,\n",
    "    iou=0.7,\n",
    "    save_json=True,            # needed for COCO-style stats\n",
    "    plots=True,                # THIS generates confusion matrix image\n",
    "    device=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2daab2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.232  Python-3.12.3 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 5070 Ti Laptop GPU, 12227MiB)\n",
      "YOLOv12s summary (fused): 159 layers, 9,249,843 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2161.8951.1 MB/s, size: 622.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/wesley/code/workzone/workzone_yolo/labels/val.cache... 2046 images, 0 backgrounds, 0 corrupt: 100%  2046/2046 1.4Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_1313e092c4d94bdf8349c99f763354b4_000000_07230.jpg: 14 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_1313e092c4d94bdf8349c99f763354b4_000000_07410.jpg: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_1313e092c4d94bdf8349c99f763354b4_000000_08220.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_1313e092c4d94bdf8349c99f763354b4_000001_08160.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_3c5d946bb34d48649217ba001b874b17_000000_07530.jpg: 8 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_3c5d946bb34d48649217ba001b874b17_000000_13830.jpg: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_3c5d946bb34d48649217ba001b874b17_000001_02610.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_3c5d946bb34d48649217ba001b874b17_000003_00570.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_43adb415eb0244ac8c5012fe05c623ba_000000_10710.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_43adb415eb0244ac8c5012fe05c623ba_000000_10830.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_72bd145a61e04b9c8d774dafe2c39f2f_000001_08040.jpg: 21 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_754820fa4bc34fd798a8b1541dd1fb7a_000001_07350.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_754820fa4bc34fd798a8b1541dd1fb7a_000001_07590.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_754820fa4bc34fd798a8b1541dd1fb7a_000001_14010.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_754820fa4bc34fd798a8b1541dd1fb7a_000002_01140.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_754820fa4bc34fd798a8b1541dd1fb7a_000002_19020.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03000.jpg: 11 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03060.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03150.jpg: 12 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03210.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03720.jpg: 11 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_786e7ec427da4ca5beb2f823840ba8d2_000001_03900.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_90d6cd5a073c411f82436941ad1372fc_000000_21930.jpg: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_b0e38fe839374b7e90fe124e4cc4b5f0_000001_20640.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_b0e38fe839374b7e90fe124e4cc4b5f0_000002_03810.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_b0e38fe839374b7e90fe124e4cc4b5f0_000002_05250.jpg: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/houston_b0e38fe839374b7e90fe124e4cc4b5f0_000002_05610.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000000_02790.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000000_08700.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000000_08820.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000002_06030.jpg: 10 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000002_23880.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_10d523eca13747e58916fb07e9ea8408_000003_00210.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000001_18270.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000001_20790.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000002_00210.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000003_09240.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000003_17340.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000003_17430.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000003_17640.jpg: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000004_01020.jpg: 13 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000004_01140.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000004_02790.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000005_20850.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000006_00360.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1aa9064a82b94a2cb9c97f3145eddf6c_000006_01020.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1af570d029aa48378193e82a5e76125e_000000_22950.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1b840ba13539483cac9db9f30a6047f6_000003_21150.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_1b840ba13539483cac9db9f30a6047f6_000003_22740.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_4240703ce3874dae8354b9f7fb20e04f_000001_11040.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_4240703ce3874dae8354b9f7fb20e04f_000002_20070.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_61c8420d09504d4a83e0946aa5491e44_000000_02430.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_61c8420d09504d4a83e0946aa5491e44_000000_02550.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_61c8420d09504d4a83e0946aa5491e44_000002_15990.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_66223187eea64275b1b9cc48ec18b808_000001_02610.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_66223187eea64275b1b9cc48ec18b808_000001_02700.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_66223187eea64275b1b9cc48ec18b808_000001_05130.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_66223187eea64275b1b9cc48ec18b808_000001_07830.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_6921f42ed03d45d2a20d1dee1ea9a9fc_000000_15360.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_6921f42ed03d45d2a20d1dee1ea9a9fc_000010_18180.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_6921f42ed03d45d2a20d1dee1ea9a9fc_000010_20100.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_8037fa57ddee41779b558f7d72d7d7fd_000002_07980.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_8037fa57ddee41779b558f7d72d7d7fd_000003_03390.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_8037fa57ddee41779b558f7d72d7d7fd_000003_04620.jpg: 6 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_8037fa57ddee41779b558f7d72d7d7fd_000003_07560.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_828ed3aacd9442cf922819cdee32dbe4_000000_00240.jpg: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_828ed3aacd9442cf922819cdee32dbe4_000000_18090.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/wesley/code/workzone/workzone_yolo/images/val/philadelphia_828ed3aacd9442cf922819cdee32dbe4_000002_05130.jpg: 8 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%  128/128 3.3it/s 38.7s0.3s\n",
      "                   all       2046      15890      0.741      0.587      0.636      0.422\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/wesley/code/workzone/runs/detect/val8\u001b[0m\n",
      "num classes in metrics: 49\n",
      "names dict: {0: 'Police Officer', 1: 'Police Vehicle', 2: 'Cone', 3: 'Fence', 4: 'Drum', 5: 'Barricade', 6: 'Barrier', 7: 'Work Vehicle', 8: 'Vertical Panel', 9: 'Tubular Marker', 10: 'Arrow Board', 11: 'Bike Lane', 12: 'Work Equipment', 13: 'Worker', 14: 'Other Roadwork Objects', 15: 'Temporary Traffic Control Message Board', 16: 'Temporary Traffic Control Sign', 17: 'Temporary Traffic Control Sign: left arrow', 18: 'Temporary Traffic Control Sign: right arrow', 19: 'Temporary Traffic Control Sign: up arrow', 20: 'Temporary Traffic Control Sign: left chevron', 21: 'Temporary Traffic Control Sign: right lane ends sign', 22: 'Temporary Traffic Control Sign: two lane shift arrows', 23: 'Temporary Traffic Control Sign: right chevron', 24: 'Temporary Traffic Control Sign: lane shift arrow', 25: 'Temporary Traffic Control Sign: up diagonal right arrow', 26: 'Temporary Traffic Control Sign: left lane ends sign', 27: 'Temporary Traffic Control Sign: bent left arrow', 28: 'Temporary Traffic Control Sign: flagger', 29: 'Temporary Traffic Control Sign: bent right arrow', 30: 'Temporary Traffic Control Sign: no left turn', 31: 'Temporary Traffic Control Sign: pedestrian: right arrow', 32: 'Temporary Traffic Control Sign: pedestrian: left arrow', 33: 'Temporary Traffic Control Sign: up diagonal left arrow', 34: 'Temporary Traffic Control Sign: pedestrian', 35: 'Temporary Traffic Control Sign: no right turn', 36: 'Temporary Traffic Control Sign: bi-directional arrow', 37: 'Temporary Traffic Control Sign: two upward diagonal arrows', 38: 'Temporary Traffic Control Sign: curved right arrow', 39: 'Temporary Traffic Control Sign: down diagonal left arrow', 40: 'Temporary Traffic Control Sign: do not enter sign', 41: 'Temporary Traffic Control Sign: worker', 42: 'Temporary Traffic Control Sign: bicycle', 43: 'Temporary Traffic Control Sign: two downward diagonal arrows', 44: 'Temporary Traffic Control Sign: curved left arrow', 45: 'Temporary Traffic Control Sign: curved left arrow, curved right arrow', 46: 'Temporary Traffic Control Sign: work vehicle', 47: 'Temporary Traffic Control Sign: traffic signal', 48: 'Temporary Traffic Control Sign: up arrow, stop sign'}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"workzone-yolo-v12/experiment-1/weights/best.pt\")\n",
    "metrics = model.val(data=\"workzone_yolo/workzone_yolo.yaml\", split=\"val\", verbose=False)\n",
    "\n",
    "print(\"num classes in metrics:\", len(metrics.names))\n",
    "print(\"names dict:\", metrics.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7793773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/wesley/code/workzone/data/demo/test2.jpg: 640x960 1 Work Vehicle, 2 Tubular Markers, 65.7ms\n",
      "Speed: 16.1ms preprocess, 65.7ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 960)\n",
      "7 Work Vehicle 0.9540051221847534\n",
      "9 Tubular Marker 0.5415558815002441\n",
      "9 Tubular Marker 0.2876492738723755\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "img_path = Path(\"data/demo/test2.jpg\")  # one with TTC sign\n",
    "res = model(img_path, conf=0.25)[0]\n",
    "\n",
    "for box in res.boxes:\n",
    "    cls_id = int(box.cls.item())\n",
    "    name = model.names[cls_id]\n",
    "    print(cls_id, name, float(box.conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4627cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-level TTC groups using your model.names indices\n",
    "TTC_GROUPS = {\n",
    "    # General TTC devices\n",
    "    \"message_board\": [15],                       # Temporary Traffic Control Message Board\n",
    "    \"generic_ttc_sign\": [16],                    # Temporary Traffic Control Sign (unspecified)\n",
    "    \"arrow_board\": [10],                         # Arrow Board\n",
    "\n",
    "    # Lane configuration / closure\n",
    "    \"lane_shift\": [22, 24, 27, 29, 37, 45],      # shift arrows, two lane shift arrows, bent arrows, two upward arrows, paired curved arrows\n",
    "    \"lane_ends\": [21, 26],                       # right lane ends, left lane ends\n",
    "    \"lane_merge_diverge\": [38, 44, 39, 43],      # curved left/right arrows, diagonal arrows\n",
    "\n",
    "    # Worker / construction warnings\n",
    "    \"worker_warning\": [28, 41],                  # flagger, worker sign\n",
    "    \"work_vehicle_sign\": [46],                   # work vehicle sign\n",
    "\n",
    "    # Pedestrian / bicycle control\n",
    "    \"pedestrian\": [31, 32, 33, 34],              # ped arrows + generic ped sign\n",
    "    \"bicycle\": [42],                             # bicycle sign\n",
    "\n",
    "    # Turn / entry control, misc regulatory\n",
    "    \"turn_restriction\": [30, 35],                # no left turn, no right turn\n",
    "    \"entry_control\": [40, 48],                   # do not enter, up arrow + stop sign\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84f126ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def summarize_ttc_groups(result, ttc_groups=TTC_GROUPS):\n",
    "    \"\"\"\n",
    "    result: one Ultralytics YOLO result object (from model(img_path)[0])\n",
    "    Returns: dict {group_name: count}\n",
    "    \"\"\"\n",
    "    cls_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
    "    counts = {g: 0 for g in ttc_groups.keys()}\n",
    "\n",
    "    for cid in cls_ids:\n",
    "        for group, idx_list in ttc_groups.items():\n",
    "            if cid in idx_list:\n",
    "                counts[group] += 1\n",
    "\n",
    "    # drop empty groups for a cleaner print\n",
    "    return {g: c for g, c in counts.items() if c > 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b477131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/wesley/code/workzone/data/demo/test1.jpg: 640x960 3 Police Officers, 2 Police Vehicles, 1 Cone, 1 Tubular Marker, 72.1ms\n",
      "Speed: 9.0ms preprocess, 72.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 960)\n",
      "Raw classes: ['Police Vehicle', 'Cone', 'Tubular Marker', 'Police Officer', 'Police Officer', 'Police Vehicle', 'Police Officer']\n",
      "TTC group summary: {}\n"
     ]
    }
   ],
   "source": [
    "img_path = \"data/demo/test1.jpg\"\n",
    "res = model(img_path, conf=0.25)[0]\n",
    "\n",
    "print(\"Raw classes:\", [model.names[int(c)] for c in res.boxes.cls])\n",
    "print(\"TTC group summary:\", summarize_ttc_groups(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4f8cf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/wesley/code/workzone/data/demo/test2.jpg: 640x960 1 Work Vehicle, 2 Tubular Markers, 27.5ms\n",
      "Speed: 4.8ms preprocess, 27.5ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 960)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['Work Vehicle', 'Tubular Marker', 'Tubular Marker']\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "YOLO_MODEL_PATH = \"workzone-yolo-v12/experiment-1/weights/best.pt\"\n",
    "IMG_PATH = \"data/demo/test2.jpg\"\n",
    "\n",
    "model = YOLO(YOLO_MODEL_PATH)\n",
    "\n",
    "results = model(IMG_PATH, conf=0.25)  # run inference\n",
    "res = results[0]\n",
    "\n",
    "annotated = res.plot()  # numpy array with boxes drawn\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.imshow(annotated)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Predicted classes:\", [model.names[int(c)] for c in res.boxes.cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5a68812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/wesley/code/workzone/data/demo/test1.jpg: 640x960 3 Police Officers, 2 Police Vehicles, 1 Cone, 1 Tubular Marker, 43.0ms\n",
      "Speed: 3.3ms preprocess, 43.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 960)\n",
      "Results saved to \u001b[1m/home/wesley/code/workzone/workzone-debug/tcc_test\u001b[0m\n",
      "Saved to: /home/wesley/code/workzone/workzone-debug/tcc_test\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "YOLO_MODEL_PATH = \"workzone-yolo-v12/experiment-1/weights/best.pt\"\n",
    "IMG_PATH = \"data/demo/test1.jpg\"\n",
    "\n",
    "model = YOLO(YOLO_MODEL_PATH)\n",
    "\n",
    "results = model(\n",
    "    source=IMG_PATH,\n",
    "    conf=0.25,\n",
    "    save=True,\n",
    "    project=\"workzone-debug\",\n",
    "    name=\"tcc_test\",\n",
    "    exist_ok=True,\n",
    ")\n",
    "\n",
    "print(\"Saved to:\", results[0].save_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workzone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
