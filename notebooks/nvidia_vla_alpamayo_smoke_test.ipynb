{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c8f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, textwrap, queue, threading\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Configuration ---\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5702e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Threaded Video Reader (The Engine) ---\n",
    "class ThreadedVideoReader(threading.Thread):\n",
    "    def __init__(self, path, queue_obj, target_size, stride=1):\n",
    "        super().__init__()\n",
    "        self.cap = cv2.VideoCapture(str(path))\n",
    "        self.queue = queue_obj\n",
    "        self.target_h, self.target_w = target_size\n",
    "        self.stride = stride\n",
    "        self.stopped = False\n",
    "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "\n",
    "    def run(self):\n",
    "        frame_idx = 0\n",
    "        while not self.stopped:\n",
    "            if self.queue.full():\n",
    "                time.sleep(0.01)\n",
    "                continue     \n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                self.stopped = True\n",
    "                break\n",
    "            \n",
    "            processed_frame = None\n",
    "            if frame_idx % self.stride == 0:\n",
    "                fr = cv2.resize(frame, (self.target_w, self.target_h))\n",
    "                fr = cv2.cvtColor(fr, cv2.COLOR_BGR2RGB)\n",
    "                processed_frame = fr\n",
    "\n",
    "            self.queue.put((frame, processed_frame))\n",
    "            frame_idx += 1\n",
    "        self.cap.release()\n",
    "\n",
    "    def stop(self): self.stopped = True\n",
    "\n",
    "# --- Threaded Video Writer (The Recorder) ---\n",
    "class ThreadedVideoWriter(threading.Thread):\n",
    "    def __init__(self, path, queue_obj, fps, width, height):\n",
    "        super().__init__()\n",
    "        self.out = cv2.VideoWriter(str(path), cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
    "        self.queue = queue_obj\n",
    "        self.stopped = False\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stopped or not self.queue.empty():\n",
    "            try:\n",
    "                frame = self.queue.get(timeout=0.1)\n",
    "                self.out.write(frame)\n",
    "                self.queue.task_done()\n",
    "            except queue.Empty: continue\n",
    "        self.out.release()\n",
    "\n",
    "    def stop(self): self.stopped = True\n",
    "\n",
    "# --- Text Helper ---\n",
    "def clean_and_wrap_text(raw_text, width=60):\n",
    "    while isinstance(raw_text, list):\n",
    "        if len(raw_text) > 0: raw_text = raw_text[0]\n",
    "        else: raw_text = \"\"\n",
    "    if hasattr(raw_text, 'decode'): raw_text = raw_text.decode(\"utf-8\", \"ignore\")\n",
    "    text = str(raw_text).replace(\"<|im_start|>\", \"\").replace(\"<|im_end|>\", \"\").strip()\n",
    "    if \"assistant\" in text: text = text.split(\"assistant\")[-1]\n",
    "    return textwrap.wrap(text.strip(), width=width), text.strip()\n",
    "\n",
    "# --- Main Logic for Notebook ---\n",
    "def run_live_notebook(video_path, model, processor, tmpl, out_path, stride=3):\n",
    "    video_path = Path(video_path)\n",
    "    \n",
    "    # 1. Setup Queues\n",
    "    read_queue = queue.Queue(maxsize=64) \n",
    "    write_queue = queue.Queue(maxsize=64)\n",
    "    T1, T2, C, tH, tW = tmpl[\"image_frames\"].shape\n",
    "    \n",
    "    # 2. Start Threads\n",
    "    reader = ThreadedVideoReader(video_path, read_queue, (tH, tW), stride=stride)\n",
    "    writer = ThreadedVideoWriter(out_path, write_queue, reader.fps, reader.width, reader.height)\n",
    "    \n",
    "    reader.start()\n",
    "    writer.start()\n",
    "\n",
    "    print(f\"Processing: {video_path.name}\")\n",
    "    \n",
    "    # --- CREATE LIVE DISPLAY WIDGET ---\n",
    "    # This widget will update in real-time in the notebook output\n",
    "    image_widget = widgets.Image(format='jpeg', width=640) # Width 640 for smooth browser performance\n",
    "    fps_label = widgets.Label(value=\"Initializing...\")\n",
    "    display(widgets.VBox([fps_label, image_widget]))\n",
    "    # ----------------------------------\n",
    "\n",
    "    cruise_xyz = torch.zeros_like(tmpl[\"ego_history_xyz\"])\n",
    "    cruise_rot = torch.zeros_like(tmpl[\"ego_history_rot\"])\n",
    "    cruise_rot[..., 0] = 1.0\n",
    "    for i in range(cruise_xyz.shape[1]):\n",
    "        cruise_xyz[0, i, 0] = 10.0 * ((i - 20) * 0.1)\n",
    "\n",
    "    frames_buffer = []      \n",
    "    model_inputs = []       \n",
    "    BATCH_SIZE = int(T1*T2)\n",
    "    \n",
    "    prev_time = time.time()\n",
    "    curr_fps = 0.0\n",
    "\n",
    "    try:\n",
    "        current_text_lines = [\"Initializing...\"]\n",
    "        \n",
    "        while True:\n",
    "            if reader.stopped and read_queue.empty(): break\n",
    "            try:\n",
    "                raw_frame, model_frame = read_queue.get(timeout=1.0)\n",
    "            except queue.Empty: continue\n",
    "\n",
    "            frames_buffer.append(raw_frame)\n",
    "            if model_frame is not None:\n",
    "                model_inputs.append(model_frame)\n",
    "\n",
    "            # --- INFERENCE ---\n",
    "            if len(model_inputs) >= BATCH_SIZE:\n",
    "                tensor = torch.from_numpy(np.stack(model_inputs)).permute(0, 3, 1, 2).unsqueeze(0)\n",
    "                messages = helper.create_message(tensor[0])\n",
    "                instruction_text = \"Output the chain-of-thought reasoning.\"\n",
    "                if isinstance(messages[0][\"content\"], list):\n",
    "                    messages[0][\"content\"].append({\"type\": \"text\", \"text\": instruction_text})\n",
    "                else: messages[0][\"content\"] = instruction_text\n",
    "\n",
    "                inputs = processor.apply_chat_template(\n",
    "                    messages, tokenize=True, add_generation_prompt=True,\n",
    "                    return_dict=True, return_tensors=\"pt\"\n",
    "                )\n",
    "                \n",
    "                inputs_data = {\n",
    "                    \"tokenized_data\": inputs,\n",
    "                    \"ego_history_xyz\": cruise_xyz, \n",
    "                    \"ego_history_rot\": cruise_rot,\n",
    "                }\n",
    "                inputs_data = helper.to_device(inputs_data, \"cuda\")\n",
    "\n",
    "                with torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "                    _, _, extra = model.sample_trajectories_from_data_with_vlm_rollout(\n",
    "                        data=inputs_data, top_p=0.8, temperature=0.6, \n",
    "                        num_traj_samples=1, max_generation_length=256, return_extra=True\n",
    "                    )\n",
    "                raw_cot = extra.get(\"cot\", [\"\"])[0]\n",
    "                current_text_lines, _ = clean_and_wrap_text(raw_cot, width=65)\n",
    "                model_inputs = []\n",
    "\n",
    "            # --- DISPLAY & SAVE ---\n",
    "            if len(frames_buffer) >= (BATCH_SIZE * stride): \n",
    "                curr_time = time.time()\n",
    "                if (curr_time - prev_time) > 0:\n",
    "                    curr_fps = len(frames_buffer) / (curr_time - prev_time)\n",
    "                prev_time = curr_time\n",
    "                \n",
    "                # Update label widget\n",
    "                fps_label.value = f\"Speed: {curr_fps:.1f} FPS\"\n",
    "\n",
    "                for fr in frames_buffer:\n",
    "                    # Draw UI\n",
    "                    banner_height = 50 + (len(current_text_lines) * 35)\n",
    "                    cv2.rectangle(fr, (0, 0), (reader.width, banner_height), (0, 0, 0), -1)\n",
    "                    \n",
    "                    # Burn FPS (Red)\n",
    "                    cv2.putText(fr, f\"FPS: {curr_fps:.1f}\", (reader.width - 250, 60), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 4)\n",
    "\n",
    "                    cv2.putText(fr, \"ALPAYMAO REASONING:\", (20, 35), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "                    y = 80\n",
    "                    for line in current_text_lines:\n",
    "                        cv2.putText(fr, line, (20, y), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "                        y += 35\n",
    "                    \n",
    "                    # 1. Send Full-Res frame to Writer (Disk)\n",
    "                    write_queue.put(fr)\n",
    "                    \n",
    "                    # 2. Send Small-Res frame to Notebook (Display)\n",
    "                    # Resize to 640px width for smooth browser playback\n",
    "                    display_h = int(640 * (reader.height / reader.width))\n",
    "                    small_view = cv2.resize(fr, (640, display_h)) \n",
    "                    _, encoded_img = cv2.imencode('.jpg', small_view)\n",
    "                    image_widget.value = encoded_img.tobytes()\n",
    "\n",
    "                frames_buffer = []\n",
    "\n",
    "    finally:\n",
    "        reader.stop()\n",
    "        writer.stop()\n",
    "        reader.join()\n",
    "        writer.join()\n",
    "        print(f\"Saved: {out_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb5bc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: jacksonville.mp4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f2ef66e09b4e639b54b6a1898319e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Initializing...'), Image(value=b'', format='jpeg', width='640')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: jacksonville_live_notebook.mp4\n"
     ]
    }
   ],
   "source": [
    "# --- Init Code (Only runs once) ---\n",
    "if 'model' not in globals():\n",
    "    ROOT = Path(\"..\").resolve()\n",
    "    if os.path.abspath(\"src\") not in sys.path:\n",
    "        sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "    from alpamayo_r1.models.alpamayo_r1 import AlpamayoR1\n",
    "    from alpamayo_r1 import helper\n",
    "    from alpamayo_r1.load_physical_aiavdataset import load_physical_aiavdataset\n",
    "\n",
    "    MODEL_ID = \"nvidia/Alpamayo-R1-10B\"\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    DTYPE = torch.bfloat16 if DEVICE == \"cuda\" else torch.float16\n",
    "\n",
    "    print(f\"Loading Model on {DEVICE}...\")\n",
    "    model = AlpamayoR1.from_pretrained(MODEL_ID, dtype=DTYPE).to(DEVICE)\n",
    "    model.eval()\n",
    "    processor = helper.get_processor(model.tokenizer)\n",
    "    \n",
    "    TEMPLATE_CLIP_ID = \"030c760c-ae38-49aa-9ad8-f5650a545d26\"\n",
    "    tmpl = load_physical_aiavdataset(TEMPLATE_CLIP_ID, t0_us=5_100_000)\n",
    "\n",
    "# Run Function\n",
    "run_live_notebook(\n",
    "    video_path=Path(\"/home/wesleyferreiramaia/data/workzone/data/demo/jacksonville.mp4\"),\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    tmpl=tmpl,\n",
    "    out_path=Path(\"jacksonville_live_notebook.mp4\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15d1b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: jacksonville.mp4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e520b58522649a2ba1c3b0c3a80221b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Initializing...'), Image(value=b'', format='jpeg', width='640')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: jacksonville_smooth_live.mp4\n"
     ]
    }
   ],
   "source": [
    "# ... (Keep your imports and class definitions for ThreadedVideoReader/Writer as they are) ...\n",
    "\n",
    "def run_live_notebook_smooth(video_path, model, processor, tmpl, out_path, stride=3):\n",
    "    video_path = Path(video_path)\n",
    "    \n",
    "    read_queue = queue.Queue(maxsize=64) \n",
    "    write_queue = queue.Queue(maxsize=64)\n",
    "    T1, T2, C, tH, tW = tmpl[\"image_frames\"].shape\n",
    "    \n",
    "    reader = ThreadedVideoReader(video_path, read_queue, (tH, tW), stride=stride)\n",
    "    writer = ThreadedVideoWriter(out_path, write_queue, reader.fps, reader.width, reader.height)\n",
    "    \n",
    "    reader.start()\n",
    "    writer.start()\n",
    "\n",
    "    print(f\"Processing: {video_path.name}\")\n",
    "    \n",
    "    # --- LIVE DISPLAY WIDGET ---\n",
    "    image_widget = widgets.Image(format='jpeg', width=640) \n",
    "    fps_label = widgets.Label(value=\"Initializing...\")\n",
    "    display(widgets.VBox([fps_label, image_widget]))\n",
    "    # ----------------------------------\n",
    "\n",
    "    cruise_xyz = torch.zeros_like(tmpl[\"ego_history_xyz\"])\n",
    "    cruise_rot = torch.zeros_like(tmpl[\"ego_history_rot\"])\n",
    "    cruise_rot[..., 0] = 1.0\n",
    "    for i in range(cruise_xyz.shape[1]):\n",
    "        cruise_xyz[0, i, 0] = 10.0 * ((i - 20) * 0.1)\n",
    "\n",
    "    frames_buffer = []      \n",
    "    model_inputs = []       \n",
    "    BATCH_SIZE = int(T1*T2)\n",
    "    \n",
    "    prev_time = time.time()\n",
    "    last_display_time = time.time() # NEW: To track display updates\n",
    "    curr_fps = 0.0\n",
    "\n",
    "    try:\n",
    "        current_text_lines = [\"Initializing...\"]\n",
    "        \n",
    "        while True:\n",
    "            if reader.stopped and read_queue.empty(): break\n",
    "            try:\n",
    "                raw_frame, model_frame = read_queue.get(timeout=1.0)\n",
    "            except queue.Empty: continue\n",
    "\n",
    "            frames_buffer.append(raw_frame)\n",
    "            if model_frame is not None:\n",
    "                model_inputs.append(model_frame)\n",
    "\n",
    "            # --- INFERENCE ---\n",
    "            if len(model_inputs) >= BATCH_SIZE:\n",
    "                tensor = torch.from_numpy(np.stack(model_inputs)).permute(0, 3, 1, 2).unsqueeze(0)\n",
    "                messages = helper.create_message(tensor[0])\n",
    "                instruction_text = \"Output the chain-of-thought reasoning.\"\n",
    "                if isinstance(messages[0][\"content\"], list):\n",
    "                    messages[0][\"content\"].append({\"type\": \"text\", \"text\": instruction_text})\n",
    "                else: messages[0][\"content\"] = instruction_text\n",
    "\n",
    "                inputs = processor.apply_chat_template(\n",
    "                    messages, tokenize=True, add_generation_prompt=True,\n",
    "                    return_dict=True, return_tensors=\"pt\"\n",
    "                )\n",
    "                \n",
    "                inputs_data = {\n",
    "                    \"tokenized_data\": inputs,\n",
    "                    \"ego_history_xyz\": cruise_xyz, \n",
    "                    \"ego_history_rot\": cruise_rot,\n",
    "                }\n",
    "                inputs_data = helper.to_device(inputs_data, \"cuda\")\n",
    "\n",
    "                with torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "                    _, _, extra = model.sample_trajectories_from_data_with_vlm_rollout(\n",
    "                        data=inputs_data, top_p=0.8, temperature=0.6, \n",
    "                        num_traj_samples=1, max_generation_length=256, return_extra=True\n",
    "                    )\n",
    "                raw_cot = extra.get(\"cot\", [\"\"])[0]\n",
    "                current_text_lines, _ = clean_and_wrap_text(raw_cot, width=65)\n",
    "                model_inputs = []\n",
    "\n",
    "            # --- DISPLAY & SAVE ---\n",
    "            if len(frames_buffer) >= (BATCH_SIZE * stride): \n",
    "                curr_time = time.time()\n",
    "                time_diff = curr_time - prev_time\n",
    "                if time_diff > 0:\n",
    "                    curr_fps = len(frames_buffer) / time_diff\n",
    "                prev_time = curr_time\n",
    "                \n",
    "                fps_label.value = f\"Processing Speed: {curr_fps:.1f} FPS\"\n",
    "\n",
    "                for fr in frames_buffer:\n",
    "                    # Draw UI\n",
    "                    banner_height = 50 + (len(current_text_lines) * 35)\n",
    "                    cv2.rectangle(fr, (0, 0), (reader.width, banner_height), (0, 0, 0), -1)\n",
    "                    cv2.putText(fr, f\"FPS: {curr_fps:.1f}\", (reader.width - 250, 60), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 4)\n",
    "                    cv2.putText(fr, \"ALPAYMAO REASONING:\", (20, 35), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "                    y = 80\n",
    "                    for line in current_text_lines:\n",
    "                        cv2.putText(fr, line, (20, y), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "                        y += 35\n",
    "                    \n",
    "                    # 1. ALWAYS Save to Disk (Full FPS)\n",
    "                    write_queue.put(fr)\n",
    "                    \n",
    "                    # 2. THROTTLED Display (Update widget max 10 times per second)\n",
    "                    # This prevents network congestion from freezing the loop\n",
    "                    if (time.time() - last_display_time) > 0.1: \n",
    "                        display_h = int(640 * (reader.height / reader.width))\n",
    "                        small_view = cv2.resize(fr, (640, display_h)) \n",
    "                        _, encoded_img = cv2.imencode('.jpg', small_view)\n",
    "                        image_widget.value = encoded_img.tobytes()\n",
    "                        last_display_time = time.time()\n",
    "\n",
    "                frames_buffer = []\n",
    "\n",
    "    finally:\n",
    "        reader.stop()\n",
    "        writer.stop()\n",
    "        reader.join()\n",
    "        writer.join()\n",
    "        print(f\"Saved: {out_path}\")\n",
    "\n",
    "# Run it\n",
    "run_live_notebook_smooth(\n",
    "    video_path=Path(\"/home/wesleyferreiramaia/data/workzone/data/demo/jacksonville.mp4\"),\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    tmpl=tmpl,\n",
    "    out_path=Path(\"jacksonville_smooth_live.mp4\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
